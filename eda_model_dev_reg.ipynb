{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc9b227f",
   "metadata": {},
   "source": [
    "# EDA - HDB Resale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Development - Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f4c859",
   "metadata": {},
   "source": [
    "### Import Environment Modules and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a965ba56",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import Python Modules\n",
    "\n",
    "## System Modules\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "import logging\n",
    "import time\n",
    "import random\n",
    "from typing import Union, Optional\n",
    "\n",
    "\n",
    "## Essential Modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "## Graphical Modules\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "## Statistical Tests\n",
    "import scipy.stats as st\n",
    "from scipy.stats import randint\n",
    "#from scipy.stats import median_abs_deviation\n",
    "from scipy.stats.mstats import kruskalwallis\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "#from statsmodels.stats.weightstats import DescrStatsW\n",
    "from statsmodels.tsa.seasonal import STL                 # trend‑seasonality split  :contentReference[oaicite:0]{index=0}\n",
    "from statsmodels.tsa.stattools import adfuller           # stationarity test      :contentReference[oaicite:1]{index=1}\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf  # autocorr lenses   :contentReference[oaicite:2]{index=2}\n",
    "\n",
    "\n",
    "## Pipeline and Train Test Split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "## SciKit Learning Preprocessing  \n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, PowerTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "### SciKit Learn ML Models\n",
    "\n",
    "## Linear Models\n",
    "from sklearn.linear_model import LinearRegression, HuberRegressor, QuantileRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "\n",
    "## Tree Based Linear Models\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "## Performance Metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, root_mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "### Hyper-parameter Tuning\n",
    "\n",
    "## GridSearch CV\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "## explicitly require this experimental feature\n",
    "from sklearn.experimental import enable_halving_search_cv # noqa\n",
    "# now you can import normally from model_selection\n",
    "from sklearn.model_selection import HalvingGridSearchCV # type: ignore\n",
    "\n",
    "## explicitly require this experimental feature\n",
    "from sklearn.experimental import enable_halving_search_cv # noqa\n",
    "# now you can import normally from model_selection\n",
    "from sklearn.model_selection import HalvingRandomSearchCV # type: ignore\n",
    "\n",
    "## Optuna for Hyperparameter Tuning\n",
    "from optuna.integration import OptunaSearchCV\n",
    "from optuna.distributions import IntDistribution, FloatDistribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b123b9",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8f272d",
   "metadata": {},
   "source": [
    "**We work for a property consultancy company. This company want to develop an end to end machine learning pipeline that could deliver housing price prediction to customer.**\n",
    "\n",
    "**Our task is to develop a machine learning model that could accurately predict the resale prices of HDB resale flats. This model will assist buyers or sellers in planning their budgets more effectively and set realistic expectations. This model also need to help buyers determine the type of flat they can afford and in which location. This model also should provide sellers with valuable information regarding the potential market value of their property.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing For Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01ada890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('./data/hdb_resale_price.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211086"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicated items\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210782"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>floor_area_sqm</th>\n",
       "      <th>lease_commence_date</th>\n",
       "      <th>resale_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>210782.000000</td>\n",
       "      <td>210782.000000</td>\n",
       "      <td>2.107820e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>96.860812</td>\n",
       "      <td>1996.336770</td>\n",
       "      <td>5.176226e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>24.038202</td>\n",
       "      <td>14.241823</td>\n",
       "      <td>1.828416e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>1966.000000</td>\n",
       "      <td>1.400000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>82.000000</td>\n",
       "      <td>1985.000000</td>\n",
       "      <td>3.800000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>93.000000</td>\n",
       "      <td>1996.000000</td>\n",
       "      <td>4.850000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>112.000000</td>\n",
       "      <td>2011.000000</td>\n",
       "      <td>6.200000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>366.700000</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>1.658888e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       floor_area_sqm  lease_commence_date  resale_price\n",
       "count   210782.000000        210782.000000  2.107820e+05\n",
       "mean        96.860812          1996.336770  5.176226e+05\n",
       "std         24.038202            14.241823  1.828416e+05\n",
       "min         31.000000          1966.000000  1.400000e+05\n",
       "25%         82.000000          1985.000000  3.800000e+05\n",
       "50%         93.000000          1996.000000  4.850000e+05\n",
       "75%        112.000000          2011.000000  6.200000e+05\n",
       "max        366.700000          2022.000000  1.658888e+06"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering - Splitting Transaction Column 'month' to Year and Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_month_to_year_month(df: pd.DataFrame, \n",
    "                              month: str = 'month',\n",
    "                              transaction_year: str = 'transaction_year',\n",
    "                              transaction_month: str = 'transaction_month') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert month column to separate year and month columns.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Input dataframe containing the month column\n",
    "    month : str, default 'month'\n",
    "        Name of the column containing month data\n",
    "    transaction_year : str, default 'transaction_year'\n",
    "        Name of the output year column\n",
    "    month_out_col : str, default 'transaction_month'\n",
    "        Name of the output month column\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Modified dataframe\n",
    "    \n",
    "    Raises:\n",
    "    -------\n",
    "    ValueError\n",
    "        If month_col doesn't exist in the dataframe\n",
    "    TypeError\n",
    "        If df is not a pandas DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    # Input validation\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError(\"Input must be a pandas DataFrame\")\n",
    "    \n",
    "    # Check if dataframe is empty\n",
    "    if df.empty:\n",
    "        warnings.warn(\"Input dataframe is empty\", UserWarning)\n",
    "        return df.copy()\n",
    "    \n",
    "    # Check if month column exists\n",
    "    if month not in df.columns:\n",
    "        raise ValueError(f\"Column '{month}' not found in dataframe\")\n",
    "    \n",
    "    # Work on copy\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Convert to datetime with error handling\n",
    "    try:\n",
    "        df[month] = pd.to_datetime(df[month], format='%Y-%m', errors='coerce')\n",
    "    except (ValueError, TypeError) as e:\n",
    "        raise ValueError(f\"Cannot convert column '{month}' to datetime: {str(e)}\")\n",
    "    \n",
    "    # Extract year and month\n",
    "    df[transaction_year] = df[month].dt.year\n",
    "    df[transaction_month] = df[month].dt.month\n",
    "    \n",
    "    # Return dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Basic functionality test passed!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SIMPLE TESTS - Run these in your notebook\n",
    "# =============================================================================\n",
    "\n",
    "def test_basic_functionality():\n",
    "    \"\"\"Test that the function works with normal data\"\"\"\n",
    "    # Create test data\n",
    "    test_df = pd.DataFrame({\n",
    "        'month': ['2023-01', '2023-02', '2023-03'],\n",
    "        'value': [100, 200, 300]\n",
    "    })\n",
    "    \n",
    "    # Run function\n",
    "    result = convert_month_to_year_month(test_df)\n",
    "    \n",
    "    # Check results\n",
    "    assert 'transaction_year' in result.columns\n",
    "    assert 'transaction_month' in result.columns\n",
    "    assert result['transaction_year'].tolist() == [2023, 2023, 2023]\n",
    "    assert result['transaction_month'].tolist() == [1, 2, 3]\n",
    "    \n",
    "    print(\"✓ Basic functionality test passed!\")\n",
    "\n",
    "\n",
    "test_basic_functionality()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Different date formats test passed!\n"
     ]
    }
   ],
   "source": [
    "def test_different_date_formats():\n",
    "    \"\"\"Test with different date formats\"\"\"\n",
    "    test_df = pd.DataFrame({\n",
    "        'month': ['2023-01', '2023-02', '2023-03'],\n",
    "        'value': [100, 200, 300]\n",
    "    })\n",
    "    \n",
    "    result = convert_month_to_year_month(test_df)\n",
    "    \n",
    "    assert result['transaction_year'].iloc[0] == 2023\n",
    "    assert result['transaction_month'].iloc[0] == 1\n",
    "    \n",
    "    print(\"✓ Different date formats test passed!\")\n",
    "\n",
    "test_different_date_formats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Null values test passed!\n"
     ]
    }
   ],
   "source": [
    "def test_with_nulls():\n",
    "    \"\"\"Test with null values\"\"\"\n",
    "    test_df = pd.DataFrame({\n",
    "        'month': ['2023-01', None, '2023-03'],\n",
    "        'value': [100, 200, 300]\n",
    "    })\n",
    "    \n",
    "    result = convert_month_to_year_month(test_df)\n",
    "    \n",
    "    # First and third rows should work\n",
    "    assert result['transaction_year'].iloc[0] == 2023\n",
    "    assert result['transaction_month'].iloc[0] == 1\n",
    "    \n",
    "    print(\"✓ Null values test passed!\")\n",
    "\n",
    "test_with_nulls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Original unchanged test passed!\n"
     ]
    }
   ],
   "source": [
    "def test_original_unchanged():\n",
    "    \"\"\"Test that original dataframe is not modified\"\"\"\n",
    "    original_df = pd.DataFrame({\n",
    "        'month': ['2023-01', '2023-02'],\n",
    "        'value': [100, 200]\n",
    "    })\n",
    "    \n",
    "    # Store original state\n",
    "    original_columns = original_df.columns.tolist()\n",
    "    \n",
    "    # Run function\n",
    "    result = convert_month_to_year_month(original_df)\n",
    "    \n",
    "    # Check original is unchanged\n",
    "    assert original_df.columns.tolist() == original_columns\n",
    "    assert 'transaction_year' not in original_df.columns\n",
    "    \n",
    "    # Check result has new columns\n",
    "    assert 'transaction_year' in result.columns\n",
    "    \n",
    "    print(\"✓ Original unchanged test passed!\")\n",
    "\n",
    "test_original_unchanged()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting column 'month' into year and month\n",
    "df = convert_month_to_year_month(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>town</th>\n",
       "      <th>flat_type</th>\n",
       "      <th>block</th>\n",
       "      <th>street_name</th>\n",
       "      <th>storey_range</th>\n",
       "      <th>floor_area_sqm</th>\n",
       "      <th>flat_model</th>\n",
       "      <th>lease_commence_date</th>\n",
       "      <th>remaining_lease</th>\n",
       "      <th>resale_price</th>\n",
       "      <th>transaction_year</th>\n",
       "      <th>transaction_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>2 ROOM</td>\n",
       "      <td>406</td>\n",
       "      <td>ANG MO KIO AVE 10</td>\n",
       "      <td>10 TO 12</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Improved</td>\n",
       "      <td>1979</td>\n",
       "      <td>61 years 04 months</td>\n",
       "      <td>232000.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>3 ROOM</td>\n",
       "      <td>108</td>\n",
       "      <td>ANG MO KIO AVE 4</td>\n",
       "      <td>01 TO 03</td>\n",
       "      <td>67.0</td>\n",
       "      <td>New Generation</td>\n",
       "      <td>1978</td>\n",
       "      <td>60 years 07 months</td>\n",
       "      <td>250000.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>3 ROOM</td>\n",
       "      <td>602</td>\n",
       "      <td>ANG MO KIO AVE 5</td>\n",
       "      <td>01 TO 03</td>\n",
       "      <td>67.0</td>\n",
       "      <td>New Generation</td>\n",
       "      <td>1980</td>\n",
       "      <td>62 years 05 months</td>\n",
       "      <td>262000.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>3 ROOM</td>\n",
       "      <td>465</td>\n",
       "      <td>ANG MO KIO AVE 10</td>\n",
       "      <td>04 TO 06</td>\n",
       "      <td>68.0</td>\n",
       "      <td>New Generation</td>\n",
       "      <td>1980</td>\n",
       "      <td>62 years 01 month</td>\n",
       "      <td>265000.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>3 ROOM</td>\n",
       "      <td>601</td>\n",
       "      <td>ANG MO KIO AVE 5</td>\n",
       "      <td>01 TO 03</td>\n",
       "      <td>67.0</td>\n",
       "      <td>New Generation</td>\n",
       "      <td>1980</td>\n",
       "      <td>62 years 05 months</td>\n",
       "      <td>265000.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       month        town flat_type block        street_name storey_range  \\\n",
       "0 2017-01-01  ANG MO KIO    2 ROOM   406  ANG MO KIO AVE 10     10 TO 12   \n",
       "1 2017-01-01  ANG MO KIO    3 ROOM   108   ANG MO KIO AVE 4     01 TO 03   \n",
       "2 2017-01-01  ANG MO KIO    3 ROOM   602   ANG MO KIO AVE 5     01 TO 03   \n",
       "3 2017-01-01  ANG MO KIO    3 ROOM   465  ANG MO KIO AVE 10     04 TO 06   \n",
       "4 2017-01-01  ANG MO KIO    3 ROOM   601   ANG MO KIO AVE 5     01 TO 03   \n",
       "\n",
       "   floor_area_sqm      flat_model  lease_commence_date     remaining_lease  \\\n",
       "0            44.0        Improved                 1979  61 years 04 months   \n",
       "1            67.0  New Generation                 1978  60 years 07 months   \n",
       "2            67.0  New Generation                 1980  62 years 05 months   \n",
       "3            68.0  New Generation                 1980   62 years 01 month   \n",
       "4            67.0  New Generation                 1980  62 years 05 months   \n",
       "\n",
       "   resale_price  transaction_year  transaction_month  \n",
       "0      232000.0              2017                  1  \n",
       "1      250000.0              2017                  1  \n",
       "2      262000.0              2017                  1  \n",
       "3      265000.0              2017                  1  \n",
       "4      265000.0              2017                  1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering - Convert 'remaining_lease' to remaining_lease_months'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_lease_to_month(lease):\n",
    "    \"\"\"\n",
    "    Convert remaining lease period from string to total number of months.\n",
    "    Args:\n",
    "        remaining_lease in (str)\n",
    "\n",
    "    Returns: \n",
    "        integer\n",
    "\n",
    "    Example:\n",
    "        convert_lease_to_month('07 TO 09') -> 8.0  \n",
    "    \"\"\"\n",
    "    str_list = lease.split(' ')\n",
    "    if ('months' in str_list) | ('month' in str_list):\n",
    "        year = int(str_list[0])\n",
    "        month = int(str_list[2])\n",
    "        t_month = (year * 12) + month \n",
    "    elif ('years' in str_list) & (('months' not in str_list) | ('month' not in str_list)):\n",
    "        year = int(str_list[0])\n",
    "        t_month = (year * 12)\n",
    "    else:\n",
    "        year = int(str_list[0])\n",
    "        t_month = (year * 12)        \n",
    "    return t_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All simple test cases passed!\n"
     ]
    }
   ],
   "source": [
    "def test_convert_lease_to_month_simple():\n",
    "    \"\"\"Simple test cases for convert_lease_to_month function\"\"\"\n",
    "    \n",
    "    # Test years and months format\n",
    "    assert convert_lease_to_month('5 years 6 months') == 66  # 5*12 + 6 = 66\n",
    "    assert convert_lease_to_month('2 years 3 months') == 27  # 2*12 + 3 = 27\n",
    "    assert convert_lease_to_month('1 years 0 months') == 12  # 1*12 + 0 = 12\n",
    "    \n",
    "    # Test years only format\n",
    "    assert convert_lease_to_month('10 years') == 120  # 10*12 = 120\n",
    "    assert convert_lease_to_month('5 years') == 60    # 5*12 = 60\n",
    "    assert convert_lease_to_month('1 years') == 12    # 1*12 = 12\n",
    "    \n",
    "    # Test with singular 'month'\n",
    "    assert convert_lease_to_month('3 years 1 month') == 37   # 3*12 + 1 = 37\n",
    "    assert convert_lease_to_month('0 years 1 month') == 1    # 0*12 + 1 = 1\n",
    "    \n",
    "    # Test just numbers (should default to years)\n",
    "    assert convert_lease_to_month('5') == 60    # 5*12 = 60\n",
    "    assert convert_lease_to_month('2') == 24    # 2*12 = 24\n",
    "    print(\"All simple test cases passed!\")\n",
    "\n",
    "test_convert_lease_to_month_simple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All variations test cases passed!\n"
     ]
    }
   ],
   "source": [
    "def test_convert_lease_to_month_variations():\n",
    "    \"\"\"Test various input formats\"\"\"\n",
    "    \n",
    "    # Test different plural/singular combinations\n",
    "    assert convert_lease_to_month('1 year 1 month') == 13    # Should work if 'year' -> 'years'\n",
    "    assert convert_lease_to_month('10 years 11 months') == 131  # 10*12 + 11 = 131\n",
    "    \n",
    "    # Test zero cases\n",
    "    assert convert_lease_to_month('0 years 6 months') == 6   # 0*12 + 6 = 6\n",
    "    assert convert_lease_to_month('0 years') == 0      \n",
    "    print(\"All variations test cases passed!\")\n",
    "\n",
    "test_convert_lease_to_month_variations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert column remaining lease to remaining lease by  months\n",
    "df['remaining_lease_by_months'] = df.remaining_lease.apply(convert_lease_to_month)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>remaining_lease</th>\n",
       "      <th>remaining_lease_by_months</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>182360</th>\n",
       "      <td>53 years 08 months</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95389</th>\n",
       "      <td>46 years 10 months</td>\n",
       "      <td>562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151225</th>\n",
       "      <td>60 years 03 months</td>\n",
       "      <td>723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132431</th>\n",
       "      <td>80 years 01 month</td>\n",
       "      <td>961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202191</th>\n",
       "      <td>57 years 05 months</td>\n",
       "      <td>689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204002</th>\n",
       "      <td>62 years 11 months</td>\n",
       "      <td>755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171330</th>\n",
       "      <td>58 years 05 months</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94807</th>\n",
       "      <td>55 years 05 months</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107717</th>\n",
       "      <td>75 years 09 months</td>\n",
       "      <td>909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117887</th>\n",
       "      <td>55 years 03 months</td>\n",
       "      <td>663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           remaining_lease  remaining_lease_by_months\n",
       "182360  53 years 08 months                        644\n",
       "95389   46 years 10 months                        562\n",
       "151225  60 years 03 months                        723\n",
       "132431   80 years 01 month                        961\n",
       "202191  57 years 05 months                        689\n",
       "204002  62 years 11 months                        755\n",
       "171330  58 years 05 months                        701\n",
       "94807   55 years 05 months                        665\n",
       "107717  75 years 09 months                        909\n",
       "117887  55 years 03 months                        663"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df[['remaining_lease', 'remaining_lease_by_months']].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering - 'storey_range'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_storey_range(storey_range):\n",
    "    \"\"\"\n",
    "    Convert storey range to the numerical average.\n",
    "    Args:\n",
    "        storey_range in (str)\n",
    "\n",
    "    Returns: \n",
    "        float\n",
    "\n",
    "    Example:\n",
    "        convert_storey_range('07 TO 09') -> 8.0 \n",
    "    \"\"\"\n",
    "\n",
    "    low, high = storey_range.split(' TO ')\n",
    "    average = (int(low) + int(high)) / 2\n",
    "    return average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All test cases passed!\n"
     ]
    }
   ],
   "source": [
    "def test_convert_storey_range():\n",
    "    \"\"\"Test cases for convert_storey_range function\"\"\"\n",
    "    \n",
    "    # Basic test case from the example\n",
    "    assert convert_storey_range('07 TO 09') == 8.0\n",
    "    \n",
    "    # Test with single digits\n",
    "    assert convert_storey_range('1 TO 3') == 2.0\n",
    "    assert convert_storey_range('5 TO 7') == 6.0\n",
    "    \n",
    "    # Test with same storey (no range)\n",
    "    assert convert_storey_range('05 TO 05') == 5.0\n",
    "    assert convert_storey_range('10 TO 10') == 10.0\n",
    "    \n",
    "    # Test with larger ranges\n",
    "    assert convert_storey_range('01 TO 05') == 3.0\n",
    "    assert convert_storey_range('10 TO 20') == 15.0\n",
    "    \n",
    "    # Test with double digits\n",
    "    assert convert_storey_range('12 TO 16') == 14.0\n",
    "    assert convert_storey_range('25 TO 35') == 30.0\n",
    "    \n",
    "    # Test with leading zeros\n",
    "    assert convert_storey_range('01 TO 03') == 2.0\n",
    "    assert convert_storey_range('08 TO 12') == 10.0\n",
    "    \n",
    "    # Test odd ranges (result should be .5)\n",
    "    assert convert_storey_range('1 TO 2') == 1.5\n",
    "    assert convert_storey_range('10 TO 11') == 10.5\n",
    "    \n",
    "    # Test with higher floors\n",
    "    assert convert_storey_range('50 TO 60') == 55.0\n",
    "    assert convert_storey_range('99 TO 101') == 100.0\n",
    "\n",
    "    print(\"All test cases passed!\")\n",
    "\n",
    "\n",
    "test_convert_storey_range()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All edge case tests passed!\n"
     ]
    }
   ],
   "source": [
    "def test_convert_storey_range_edge_cases():\n",
    "    \"\"\"Test edge cases and potential error scenarios\"\"\"\n",
    "    \n",
    "    # Test ground floor scenarios\n",
    "    assert convert_storey_range('0 TO 2') == 1.0\n",
    "    assert convert_storey_range('00 TO 01') == 0.5\n",
    "    \n",
    "    # Test with mixed formatting\n",
    "    assert convert_storey_range('5 TO 15') == 10.0\n",
    "    assert convert_storey_range('02 TO 8') == 5.0\n",
    "\n",
    "    print(\"All edge case tests passed!\")\n",
    "\n",
    "test_convert_storey_range_edge_cases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All error handling tests passed!\n"
     ]
    }
   ],
   "source": [
    "import pytest\n",
    "def test_convert_storey_range_errors():\n",
    "    \"\"\"Test error handling scenarios\"\"\"\n",
    "    \n",
    "    # Test invalid format (should raise ValueError)\n",
    "    with pytest.raises(ValueError):\n",
    "        convert_storey_range('invalid format')\n",
    "    \n",
    "    with pytest.raises(ValueError):\n",
    "        convert_storey_range('5-7')  # Wrong separator\n",
    "    \n",
    "    with pytest.raises(ValueError):\n",
    "        convert_storey_range('5 TO')  # Missing high value\n",
    "    \n",
    "    with pytest.raises(ValueError):\n",
    "        convert_storey_range('TO 7')  # Missing low value\n",
    "    \n",
    "    # Test non-numeric values\n",
    "    with pytest.raises(ValueError):\n",
    "        convert_storey_range('A TO B')\n",
    "    \n",
    "    with pytest.raises(ValueError):\n",
    "        convert_storey_range('1 TO B')\n",
    "\n",
    "    print(\"All error handling tests passed!\")\n",
    "\n",
    "test_convert_storey_range_errors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic functionality test passed!\n",
      "Same storey test passed!\n",
      "Decimal results test passed!\n",
      "Invalid input test passed!\n"
     ]
    }
   ],
   "source": [
    "# Alternative test format using unittest if you prefer\n",
    "import unittest\n",
    "\n",
    "class TestConvertStoreyRange(unittest.TestCase):\n",
    "    \n",
    "    def test_basic_functionality(self):\n",
    "        \"\"\"Test basic functionality\"\"\"\n",
    "        self.assertEqual(convert_storey_range('07 TO 09'), 8.0)\n",
    "        self.assertEqual(convert_storey_range('1 TO 3'), 2.0)\n",
    "        self.assertEqual(convert_storey_range('10 TO 20'), 15.0)\n",
    "        print(\"Basic functionality test passed!\")\n",
    "    \n",
    "    def test_same_storey(self):\n",
    "        \"\"\"Test when low and high are the same\"\"\"\n",
    "        self.assertEqual(convert_storey_range('05 TO 05'), 5.0)\n",
    "        self.assertEqual(convert_storey_range('10 TO 10'), 10.0)\n",
    "        print(\"Same storey test passed!\")\n",
    "    \n",
    "    def test_decimal_results(self):\n",
    "        \"\"\"Test cases that result in decimal values\"\"\"\n",
    "        self.assertEqual(convert_storey_range('1 TO 2'), 1.5)\n",
    "        self.assertEqual(convert_storey_range('10 TO 11'), 10.5)\n",
    "        print(\"Decimal results test passed!\")\n",
    "    \n",
    "    def test_invalid_input(self):\n",
    "        \"\"\"Test invalid input handling\"\"\"\n",
    "        with self.assertRaises(ValueError):\n",
    "            convert_storey_range('invalid')\n",
    "        with self.assertRaises(ValueError):\n",
    "            convert_storey_range('A TO B')\n",
    "        print(\"Invalid input test passed!\")\n",
    "\n",
    "\n",
    "unit_test = TestConvertStoreyRange()\n",
    "unit_test.test_basic_functionality()\n",
    "unit_test.test_same_storey()\n",
    "unit_test.test_decimal_results()\n",
    "unit_test.test_invalid_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert storey range to number middle value\n",
    "df['storey_range'] = df.storey_range.apply(convert_storey_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>town</th>\n",
       "      <th>flat_type</th>\n",
       "      <th>block</th>\n",
       "      <th>street_name</th>\n",
       "      <th>storey_range</th>\n",
       "      <th>floor_area_sqm</th>\n",
       "      <th>flat_model</th>\n",
       "      <th>lease_commence_date</th>\n",
       "      <th>remaining_lease</th>\n",
       "      <th>resale_price</th>\n",
       "      <th>transaction_year</th>\n",
       "      <th>transaction_month</th>\n",
       "      <th>remaining_lease_by_months</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>2 ROOM</td>\n",
       "      <td>406</td>\n",
       "      <td>ANG MO KIO AVE 10</td>\n",
       "      <td>11.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Improved</td>\n",
       "      <td>1979</td>\n",
       "      <td>61 years 04 months</td>\n",
       "      <td>232000.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>3 ROOM</td>\n",
       "      <td>108</td>\n",
       "      <td>ANG MO KIO AVE 4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>New Generation</td>\n",
       "      <td>1978</td>\n",
       "      <td>60 years 07 months</td>\n",
       "      <td>250000.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>3 ROOM</td>\n",
       "      <td>602</td>\n",
       "      <td>ANG MO KIO AVE 5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>New Generation</td>\n",
       "      <td>1980</td>\n",
       "      <td>62 years 05 months</td>\n",
       "      <td>262000.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>3 ROOM</td>\n",
       "      <td>465</td>\n",
       "      <td>ANG MO KIO AVE 10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>New Generation</td>\n",
       "      <td>1980</td>\n",
       "      <td>62 years 01 month</td>\n",
       "      <td>265000.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>3 ROOM</td>\n",
       "      <td>601</td>\n",
       "      <td>ANG MO KIO AVE 5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>New Generation</td>\n",
       "      <td>1980</td>\n",
       "      <td>62 years 05 months</td>\n",
       "      <td>265000.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       month        town flat_type block        street_name  storey_range  \\\n",
       "0 2017-01-01  ANG MO KIO    2 ROOM   406  ANG MO KIO AVE 10          11.0   \n",
       "1 2017-01-01  ANG MO KIO    3 ROOM   108   ANG MO KIO AVE 4           2.0   \n",
       "2 2017-01-01  ANG MO KIO    3 ROOM   602   ANG MO KIO AVE 5           2.0   \n",
       "3 2017-01-01  ANG MO KIO    3 ROOM   465  ANG MO KIO AVE 10           5.0   \n",
       "4 2017-01-01  ANG MO KIO    3 ROOM   601   ANG MO KIO AVE 5           2.0   \n",
       "\n",
       "   floor_area_sqm      flat_model  lease_commence_date     remaining_lease  \\\n",
       "0            44.0        Improved                 1979  61 years 04 months   \n",
       "1            67.0  New Generation                 1978  60 years 07 months   \n",
       "2            67.0  New Generation                 1980  62 years 05 months   \n",
       "3            68.0  New Generation                 1980   62 years 01 month   \n",
       "4            67.0  New Generation                 1980  62 years 05 months   \n",
       "\n",
       "   resale_price  transaction_year  transaction_month  \\\n",
       "0      232000.0              2017                  1   \n",
       "1      250000.0              2017                  1   \n",
       "2      262000.0              2017                  1   \n",
       "3      265000.0              2017                  1   \n",
       "4      265000.0              2017                  1   \n",
       "\n",
       "   remaining_lease_by_months  \n",
       "0                        736  \n",
       "1                        727  \n",
       "2                        749  \n",
       "3                        745  \n",
       "4                        749  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Irrelevant Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping irrelevant columns for machine learning preparation\n",
    "# Keep month for temporal sorting and split, will remove later\n",
    "irrelevant_columns = ['block', 'street_name', 'remaining_lease', 'lease_commence_date']\n",
    "df.drop(columns = irrelevant_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>town</th>\n",
       "      <th>flat_type</th>\n",
       "      <th>storey_range</th>\n",
       "      <th>floor_area_sqm</th>\n",
       "      <th>flat_model</th>\n",
       "      <th>resale_price</th>\n",
       "      <th>transaction_year</th>\n",
       "      <th>transaction_month</th>\n",
       "      <th>remaining_lease_by_months</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>2 ROOM</td>\n",
       "      <td>11.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Improved</td>\n",
       "      <td>232000.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>3 ROOM</td>\n",
       "      <td>2.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>New Generation</td>\n",
       "      <td>250000.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>3 ROOM</td>\n",
       "      <td>2.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>New Generation</td>\n",
       "      <td>262000.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>3 ROOM</td>\n",
       "      <td>5.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>New Generation</td>\n",
       "      <td>265000.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>3 ROOM</td>\n",
       "      <td>2.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>New Generation</td>\n",
       "      <td>265000.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       month        town flat_type  storey_range  floor_area_sqm  \\\n",
       "0 2017-01-01  ANG MO KIO    2 ROOM          11.0            44.0   \n",
       "1 2017-01-01  ANG MO KIO    3 ROOM           2.0            67.0   \n",
       "2 2017-01-01  ANG MO KIO    3 ROOM           2.0            67.0   \n",
       "3 2017-01-01  ANG MO KIO    3 ROOM           5.0            68.0   \n",
       "4 2017-01-01  ANG MO KIO    3 ROOM           2.0            67.0   \n",
       "\n",
       "       flat_model  resale_price  transaction_year  transaction_month  \\\n",
       "0        Improved      232000.0              2017                  1   \n",
       "1  New Generation      250000.0              2017                  1   \n",
       "2  New Generation      262000.0              2017                  1   \n",
       "3  New Generation      265000.0              2017                  1   \n",
       "4  New Generation      265000.0              2017                  1   \n",
       "\n",
       "   remaining_lease_by_months  \n",
       "0                        736  \n",
       "1                        727  \n",
       "2                        749  \n",
       "3                        745  \n",
       "4                        749  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['month', 'town', 'flat_type', 'storey_range', 'floor_area_sqm',\n",
       "       'flat_model', 'resale_price', 'transaction_year', 'transaction_month',\n",
       "       'remaining_lease_by_months'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 210782 entries, 0 to 211085\n",
      "Data columns (total 10 columns):\n",
      " #   Column                     Non-Null Count   Dtype         \n",
      "---  ------                     --------------   -----         \n",
      " 0   month                      210782 non-null  datetime64[ns]\n",
      " 1   town                       210782 non-null  object        \n",
      " 2   flat_type                  210782 non-null  object        \n",
      " 3   storey_range               210782 non-null  float64       \n",
      " 4   floor_area_sqm             210782 non-null  float64       \n",
      " 5   flat_model                 210782 non-null  object        \n",
      " 6   resale_price               210782 non-null  float64       \n",
      " 7   transaction_year           210782 non-null  int32         \n",
      " 8   transaction_month          210782 non-null  int32         \n",
      " 9   remaining_lease_by_months  210782 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(3), int32(2), int64(1), object(3)\n",
      "memory usage: 16.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temporal = df.set_index('month').sort_index().copy() \n",
    "y_temporal = X_temporal['resale_price']\n",
    "X_temporal = X_temporal.drop(columns=['resale_price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>town</th>\n",
       "      <th>flat_type</th>\n",
       "      <th>storey_range</th>\n",
       "      <th>floor_area_sqm</th>\n",
       "      <th>flat_model</th>\n",
       "      <th>transaction_year</th>\n",
       "      <th>transaction_month</th>\n",
       "      <th>remaining_lease_by_months</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01</th>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>2 ROOM</td>\n",
       "      <td>11.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Improved</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01</th>\n",
       "      <td>SEMBAWANG</td>\n",
       "      <td>4 ROOM</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Model A</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01</th>\n",
       "      <td>SEMBAWANG</td>\n",
       "      <td>4 ROOM</td>\n",
       "      <td>5.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Model A</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01</th>\n",
       "      <td>SEMBAWANG</td>\n",
       "      <td>4 ROOM</td>\n",
       "      <td>2.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>Model A2</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01</th>\n",
       "      <td>QUEENSTOWN</td>\n",
       "      <td>5 ROOM</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>Improved</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  town flat_type  storey_range  floor_area_sqm flat_model  \\\n",
       "month                                                                       \n",
       "2017-01-01  ANG MO KIO    2 ROOM          11.0            44.0   Improved   \n",
       "2017-01-01   SEMBAWANG    4 ROOM           2.0           100.0    Model A   \n",
       "2017-01-01   SEMBAWANG    4 ROOM           5.0           100.0    Model A   \n",
       "2017-01-01   SEMBAWANG    4 ROOM           2.0            86.0   Model A2   \n",
       "2017-01-01  QUEENSTOWN    5 ROOM          20.0           110.0   Improved   \n",
       "\n",
       "            transaction_year  transaction_month  remaining_lease_by_months  \n",
       "month                                                                       \n",
       "2017-01-01              2017                  1                        736  \n",
       "2017-01-01              2017                  1                        981  \n",
       "2017-01-01              2017                  1                        976  \n",
       "2017-01-01              2017                  1                        990  \n",
       "2017-01-01              2017                  1                       1067  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_temporal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "month\n",
       "2017-01-01    232000.0\n",
       "2017-01-01    342000.0\n",
       "2017-01-01    335000.0\n",
       "2017-01-01    305000.0\n",
       "2017-01-01    860000.0\n",
       "Name: resale_price, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_temporal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_temporal shape: (210782, 8)\n",
      "y_temporal shape: (210782,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_temporal shape:\", X_temporal.shape)\n",
    "print(\"y_temporal shape:\", y_temporal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2022-05-01 00:00:00')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find split date for training and validation\n",
    "split_date_train = df['month'].quantile(0.6)\n",
    "split_date_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2023-12-01 00:00:00')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_date_validation = df['month'].quantile(0.8) \n",
    "split_date_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets in a temporal manner\n",
    "X_train_temporal = X_temporal[X_temporal.index < split_date_train]\n",
    "y_train_temporal = y_temporal[y_temporal.index < split_date_train]\n",
    "X_validation_temporal = X_temporal[(X_temporal.index >= split_date_train) & (X_temporal.index < split_date_validation)]\n",
    "y_validation_temporal = y_temporal[(y_temporal.index >= split_date_train) & (y_temporal.index < split_date_validation)]\n",
    "X_test_temporal = X_temporal[X_temporal.index >= split_date_validation]\n",
    "y_test_temporal = y_temporal[y_temporal.index >= split_date_validation]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal Training set shape: (125284, 8) (125284,)\n",
      "Temporal Validation set shape: (41584, 8) (41584,)\n",
      "Temporal Test set shape: (43914, 8) (43914,)\n"
     ]
    }
   ],
   "source": [
    "# Display the shapes of the splits to verify\n",
    "print(\"Temporal Training set shape:\", X_train_temporal.shape, y_train_temporal.shape)\n",
    "print(\"Temporal Validation set shape:\", X_validation_temporal.shape, y_validation_temporal.shape)\n",
    "print(\"Temporal Test set shape:\", X_test_temporal.shape, y_test_temporal.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Split Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['month'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the data into features and target\n",
    "X = df.drop(columns='resale_price').copy()\n",
    "y = df['resale_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (210782, 8)\n",
      "y shape: (210782,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>town</th>\n",
       "      <th>flat_type</th>\n",
       "      <th>storey_range</th>\n",
       "      <th>floor_area_sqm</th>\n",
       "      <th>flat_model</th>\n",
       "      <th>transaction_year</th>\n",
       "      <th>transaction_month</th>\n",
       "      <th>remaining_lease_by_months</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>2 ROOM</td>\n",
       "      <td>11.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Improved</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>3 ROOM</td>\n",
       "      <td>2.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>New Generation</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>3 ROOM</td>\n",
       "      <td>2.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>New Generation</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>3 ROOM</td>\n",
       "      <td>5.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>New Generation</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>3 ROOM</td>\n",
       "      <td>2.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>New Generation</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         town flat_type  storey_range  floor_area_sqm      flat_model  \\\n",
       "0  ANG MO KIO    2 ROOM          11.0            44.0        Improved   \n",
       "1  ANG MO KIO    3 ROOM           2.0            67.0  New Generation   \n",
       "2  ANG MO KIO    3 ROOM           2.0            67.0  New Generation   \n",
       "3  ANG MO KIO    3 ROOM           5.0            68.0  New Generation   \n",
       "4  ANG MO KIO    3 ROOM           2.0            67.0  New Generation   \n",
       "\n",
       "   transaction_year  transaction_month  remaining_lease_by_months  \n",
       "0              2017                  1                        736  \n",
       "1              2017                  1                        727  \n",
       "2              2017                  1                        749  \n",
       "3              2017                  1                        745  \n",
       "4              2017                  1                        749  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    232000.0\n",
       "1    250000.0\n",
       "2    262000.0\n",
       "3    265000.0\n",
       "4    265000.0\n",
       "Name: resale_price, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training (60%) and test-validation (40%) sets\n",
    "X_train, X_validation_and_test, y_train, y_validation_and_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Split the test-validation set (40%) into validation (20%) and test (20%) sets\n",
    "X_validation, X_test, y_validation, y_test = train_test_split(X_validation_and_test, y_validation_and_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (126469, 8) (126469,)\n",
      "Validation set shape: (42156, 8) (42156,)\n",
      "Test set shape: (42157, 8) (42157,)\n"
     ]
    }
   ],
   "source": [
    "# Display the shapes of the splits to verify\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation set shape:\", X_validation.shape, y_validation.shape)\n",
    "print(\"Test set shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>town</th>\n",
       "      <th>flat_type</th>\n",
       "      <th>storey_range</th>\n",
       "      <th>floor_area_sqm</th>\n",
       "      <th>flat_model</th>\n",
       "      <th>transaction_year</th>\n",
       "      <th>transaction_month</th>\n",
       "      <th>remaining_lease_by_months</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8447</th>\n",
       "      <td>CHOA CHU KANG</td>\n",
       "      <td>4 ROOM</td>\n",
       "      <td>8.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>Model A</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64263</th>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>3 ROOM</td>\n",
       "      <td>5.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>New Generation</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144387</th>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>3 ROOM</td>\n",
       "      <td>11.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>New Generation</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19535</th>\n",
       "      <td>JURONG EAST</td>\n",
       "      <td>3 ROOM</td>\n",
       "      <td>5.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>Improved</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157883</th>\n",
       "      <td>PUNGGOL</td>\n",
       "      <td>5 ROOM</td>\n",
       "      <td>14.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>Premium Apartment</td>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "      <td>960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 town flat_type  storey_range  floor_area_sqm  \\\n",
       "8447    CHOA CHU KANG    4 ROOM           8.0           104.0   \n",
       "64263      ANG MO KIO    3 ROOM           5.0            82.0   \n",
       "144387     ANG MO KIO    3 ROOM          11.0            81.0   \n",
       "19535     JURONG EAST    3 ROOM           5.0            86.0   \n",
       "157883        PUNGGOL    5 ROOM          14.0           114.0   \n",
       "\n",
       "               flat_model  transaction_year  transaction_month  \\\n",
       "8447              Model A              2017                  6   \n",
       "64263      New Generation              2020                  1   \n",
       "144387     New Generation              2023                 12   \n",
       "19535            Improved              2017                 12   \n",
       "157883  Premium Apartment              2023                  6   \n",
       "\n",
       "        remaining_lease_by_months  \n",
       "8447                          850  \n",
       "64263                         710  \n",
       "144387                        667  \n",
       "19535                         725  \n",
       "157883                        960  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = X_train.select_dtypes(include='number').columns.tolist()\n",
    "categorical_columns = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "temporal_columns = X_train.select_dtypes(include=['datetime']).columns.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['storey_range',\n",
       " 'floor_area_sqm',\n",
       " 'transaction_year',\n",
       " 'transaction_month',\n",
       " 'remaining_lease_by_months']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['town', 'flat_type', 'flat_model']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temporal_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns that are numerical for feature scaling preparation\n",
    "numerical_features = ['floor_area_sqm', 'remaining_lease_by_months', 'transac_year'] \n",
    "\n",
    "degree = 1  # Degree of polynomial features, can be adjusted\n",
    "# Create a numerical transformer pipeline\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('polynomial_features', PolynomialFeatures(degree=degree)),  # Placeholder for polynomial features\n",
    "    ('scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns that need to be one-hot encoded\n",
    "nominal_features = ['transac_month', 'town', 'flat_model', 'flat_type']\n",
    "\n",
    "# Select the columns that do not required further processing \n",
    "passthrough_features = ['storey_range']\n",
    "\n",
    "# Setting pipeline for one-hot encoding\n",
    "nominal_transformer = Pipeline(steps=[\n",
    "    ('one_hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical features: ['floor_area_sqm', 'remaining_lease_by_months', 'transac_year']\n",
      "Nominal features: ['transac_month', 'town', 'flat_model', 'flat_type']\n",
      "Passthrough features: ['storey_range']\n"
     ]
    }
   ],
   "source": [
    "# print numerical, nominal and passthrough features\n",
    "print(\"Numerical features:\", numerical_features)\n",
    "print(\"Nominal features:\", nominal_features)    \n",
    "print(\"Passthrough features:\", passthrough_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = 1  # Degree of polynomial features, can be adjusted\n",
    "# Create a numerical transformer pipeline\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('polynomial_features', PolynomialFeatures(degree=degree)),  # Placeholder for polynomial features\n",
    "    ('scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting pipeline for one-hot encoding\n",
    "nominal_transformer = Pipeline(steps=[\n",
    "    ('one_hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('nom', nominal_transformer, nominal_features),\n",
    "        ('pass', 'passthrough', passthrough_features) \n",
    "    ],\n",
    "    remainder='passthrough',\n",
    "    n_jobs=-1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(n_jobs=-1, remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;polynomial_features&#x27;,\n",
       "                                                  PolynomialFeatures(degree=1)),\n",
       "                                                 (&#x27;scaler&#x27;, StandardScaler())]),\n",
       "                                 [&#x27;floor_area_sqm&#x27;, &#x27;remaining_lease_by_months&#x27;,\n",
       "                                  &#x27;transac_year&#x27;]),\n",
       "                                (&#x27;nom&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;one_hot&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                 [&#x27;transac_month&#x27;, &#x27;town&#x27;, &#x27;flat_model&#x27;,\n",
       "                                  &#x27;flat_type&#x27;]),\n",
       "                                (&#x27;pass&#x27;, &#x27;passthrough&#x27;, [&#x27;storey_range&#x27;])])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>ColumnTransformer</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for ColumnTransformer</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></div></label><div class=\"sk-toggleable__content \"><pre>ColumnTransformer(n_jobs=-1, remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;polynomial_features&#x27;,\n",
       "                                                  PolynomialFeatures(degree=1)),\n",
       "                                                 (&#x27;scaler&#x27;, StandardScaler())]),\n",
       "                                 [&#x27;floor_area_sqm&#x27;, &#x27;remaining_lease_by_months&#x27;,\n",
       "                                  &#x27;transac_year&#x27;]),\n",
       "                                (&#x27;nom&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;one_hot&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                 [&#x27;transac_month&#x27;, &#x27;town&#x27;, &#x27;flat_model&#x27;,\n",
       "                                  &#x27;flat_type&#x27;]),\n",
       "                                (&#x27;pass&#x27;, &#x27;passthrough&#x27;, [&#x27;storey_range&#x27;])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>num</div></div></label><div class=\"sk-toggleable__content \"><pre>[&#x27;floor_area_sqm&#x27;, &#x27;remaining_lease_by_months&#x27;, &#x27;transac_year&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>PolynomialFeatures</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.PolynomialFeatures.html\">?<span>Documentation for PolynomialFeatures</span></a></div></label><div class=\"sk-toggleable__content \"><pre>PolynomialFeatures(degree=1)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></div></label><div class=\"sk-toggleable__content \"><pre>StandardScaler()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>nom</div></div></label><div class=\"sk-toggleable__content \"><pre>[&#x27;transac_month&#x27;, &#x27;town&#x27;, &#x27;flat_model&#x27;, &#x27;flat_type&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>OneHotEncoder</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></div></label><div class=\"sk-toggleable__content \"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>pass</div></div></label><div class=\"sk-toggleable__content \"><pre>[&#x27;storey_range&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>passthrough</div></div></label><div class=\"sk-toggleable__content \"><pre>passthrough</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>remainder</div></div></label><div class=\"sk-toggleable__content \"><pre></pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>passthrough</div></div></label><div class=\"sk-toggleable__content \"><pre>passthrough</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ColumnTransformer(n_jobs=-1, remainder='passthrough',\n",
       "                  transformers=[('num',\n",
       "                                 Pipeline(steps=[('polynomial_features',\n",
       "                                                  PolynomialFeatures(degree=1)),\n",
       "                                                 ('scaler', StandardScaler())]),\n",
       "                                 ['floor_area_sqm', 'remaining_lease_by_months',\n",
       "                                  'transac_year']),\n",
       "                                ('nom',\n",
       "                                 Pipeline(steps=[('one_hot',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                 ['transac_month', 'town', 'flat_model',\n",
       "                                  'flat_type']),\n",
       "                                ('pass', 'passthrough', ['storey_range'])])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Development - Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate Linear Regression without Target Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up regression pipeline\n",
    "lr_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model fitting\n",
    "lr_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on validation set\n",
    "y_val_pred = lr_pipeline.predict(X_val)\n",
    "y_val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature names after preprocessing\n",
    "feature_names = lr_pipeline.named_steps['preprocessor'].get_feature_names_out()\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model coefficients\n",
    "model_coefficients = lr_pipeline.named_steps['regressor'].coef_\n",
    "print(model_coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate regression metrics for validation set\n",
    "lr_val_mae = mean_absolute_error(y_val, y_val_pred)\n",
    "lr_val_mse = mean_squared_error(y_val, y_val_pred)\n",
    "lr_val_rmse = root_mean_squared_error(y_val, y_val_pred)  \n",
    "lr_val_r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "# Display the metrics\n",
    "print('Linear Regression Performance Metrics:')\n",
    "print(f\"Linear Regression Validation MAE: {lr_val_mae}\")\n",
    "print(f\"Linear Regression Validation MSE: {lr_val_mse}\")\n",
    "print(f\"Linear Regression Validation RMSE: {lr_val_rmse}\")\n",
    "print(f\"Linear Regression Validation R2: {lr_val_r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Residual Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual analysis\n",
    "residuals = y_val - y_val_pred[0]\n",
    "# Plotting residuals\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_val_pred, residuals, alpha=0.5)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.title('Residuals vs Predicted Values')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# residual distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(residuals, kde=True, bins=30)\n",
    "plt.title('Residuals Distribution')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Residual plot shows that the model did not capture non-linearity in the target. Residual distribution remains skewed. Will try target transformation.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate Linear Regression with Target Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = PowerTransformer(method='yeo-johnson')\n",
    "y_train_transformed = pt.fit_transform(y_train.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the transformed target variable\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(y_train_transformed, kde=True, bins=30)\n",
    "plt.title('Transformed Target Variable Distribution')\n",
    "plt.xlabel('Transformed Resale Price')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model fitting\n",
    "lr_pipeline.fit(X_train, y_train_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on validation set\n",
    "y_val_pred_transformed = lr_pipeline.predict(X_val)\n",
    "#print(type(y_val_pred_transformed))\n",
    "#print(y_val_pred_transformed.shape)\n",
    "y_val_pred = pt.inverse_transform(y_val_pred_transformed.reshape(-1, 1))  # type: ignore # Inverse transform to get original scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate regression metrics for validation set\n",
    "lr_val_mae_transformed = mean_absolute_error(y_val, y_val_pred)\n",
    "lr_val_mse_transformed = mean_squared_error(y_val, y_val_pred)\n",
    "lr_val_rmse_transformed = root_mean_squared_error(y_val, y_val_pred)  \n",
    "lr_val_r2_transformed = r2_score(y_val, y_val_pred)\n",
    "\n",
    "\n",
    "# Display the metrics\n",
    "print(f\"Validation MAE (Transformed): {lr_val_mae_transformed}\")\n",
    "print(f\"Validation MSE (Transformed): {lr_val_mse_transformed}\")\n",
    "print(f\"Validation RMSE (Transformed): {lr_val_rmse_transformed}\")\n",
    "print(f\"Validation R2 (Transformed): {lr_val_r2_transformed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual analysis\n",
    "residuals = y_val - y_val_pred[0]\n",
    "\n",
    "# Plotting residuals\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_val_pred, residuals, alpha=0.5)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.title('Residuals vs Predicted Values (Transformed)')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(residuals, kde=True, bins=30)\n",
    "plt.title('Residuals Distribution (Transformed)')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# residual plot in transform space\n",
    "y_pred_t = lr_pipeline.predict(X_val)          \n",
    "if isinstance(y_pred_t, tuple):\n",
    "\ty_pred_t_flat = y_pred_t[0].flatten()\n",
    "else:\n",
    "\ty_pred_t_flat = y_pred_t.flatten()\n",
    "resid_t = y_train_transformed.flatten()[:len(y_pred_t_flat)] - y_pred_t_flat\n",
    "plt.scatter(y_pred_t_flat, resid_t, alpha=0.3)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.title(\"Residuals vs Predicted (Transformed Space)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparing the residual plot after target transformation, we can see that linear regression could not catch non-linearity.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the metrics\n",
    "print(f\"Validation MAE: {lr_val_mae}\")\n",
    "print(f\"Validation MSE: {lr_val_mse}\")\n",
    "print(f\"Validation RMSE: {lr_val_rmse}\")\n",
    "print(f\"Validation R2: {lr_val_r2}\")\n",
    "\n",
    "# Display the metrics\n",
    "print(f\"Validation MAE (Transformed): {lr_val_mae_transformed}\")\n",
    "print(f\"Validation MSE (Transformed): {lr_val_mse_transformed}\")\n",
    "print(f\"Validation RMSE (Transformed): {lr_val_rmse_transformed}\")\n",
    "print(f\"Validation R2 (Transformed): {lr_val_r2_transformed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transformation likely helped normalize the error distribution and reduce the impact of large errors (outliers) in the transformed space. This makes the model more accurate on average, leading to a better Mean Absolute Error.\n",
    "\n",
    "RMSE got worst and there is a slight dip in R-squared due to the inverse transformation. While the model might be performing well in the transformed scale, any prediction errors, particularly those on the higher end of the original data, get magnified when inverse transformed back to the original scale. Since RMSE heavily penalizes these larger errors (by squaring them), it increases. This overall increase in magnified errors also leads to a slight decrease in R-squared, as the model explains less of the variance in the original scale.\n",
    "\n",
    "Essentially, the transformation optimized for model performance in a normalized space, but the re-scaling back to the original units amplified certain errors, negatively impacting RMSE and R-squared."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transformed target did decrease MAE, which is our business objective, residual plot shows that the model failed to capture non-linearity. We will test with Polynomial regression, Ridge and Lasso regression. Will also try Huber Regression and Quantile Regression.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Regression with/without Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = 2  # Degree of polynomial features, can be adjusted\n",
    "# Create a numerical transformer pipeline\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('polynomial_features', PolynomialFeatures(degree=degree)),  # Placeholder for polynomial features\n",
    "    ('scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('nom', nominal_transformer, nominal_features),\n",
    "        ('pass', 'passthrough', passthrough_features) \n",
    "    ],\n",
    "    remainder='passthrough',\n",
    "    n_jobs=-1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up regression pipeline\n",
    "lr_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polynomial Regression (No Transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = lr_pipeline.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate regression metrics for validation set\n",
    "poly_val_mae = mean_absolute_error(y_val, y_val_pred)\n",
    "poly_val_mse = mean_squared_error(y_val, y_val_pred)\n",
    "poly_val_rmse = root_mean_squared_error(y_val, y_val_pred)  \n",
    "poly_val_r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "# Display the metrics\n",
    "print(f\"Validation MAE: {poly_val_mae}\")\n",
    "print(f\"Validation MSE: {poly_val_mse}\")\n",
    "print(f\"Validation RMSE: {poly_val_rmse}\")\n",
    "print(f\"Validation R2: {poly_val_r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polynomial Regression (Transformed Target Regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TransformedTargetRegressor_model = TransformedTargetRegressor(\n",
    "    regressor    = lr_pipeline,\n",
    "    transformer  = PowerTransformer(method='yeo-johnson')\n",
    ")\n",
    "TransformedTargetRegressor_model.fit(X_train, y_train)\n",
    "y_val_pred = TransformedTargetRegressor_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate regression metrics for validation set\n",
    "poly_val_mae_transformed = mean_absolute_error(y_val, y_val_pred)\n",
    "poly_val_mse_transformed = mean_squared_error(y_val, y_val_pred)\n",
    "poly_val_rmse_transformed = root_mean_squared_error(y_val, y_val_pred)  \n",
    "poly_val_r2_transformed = r2_score(y_val, y_val_pred)\n",
    "\n",
    "# Display the metrics\n",
    "print(f\"Polynomial Regression Validation MAE with {degree} polynomial degree: {poly_val_mae}\")\n",
    "print(f\"Polynomial Regression Validation MSE with {degree} polynomial degree: {poly_val_mse}\")\n",
    "print(f\"Polynomial Regression Validation RMSE with {degree} polynomial degree: {poly_val_rmse}\")\n",
    "print(f\"Polynomial Regression Validation R2 with {degree} polynomial degree: {poly_val_r2}\")\n",
    "\n",
    "# Display the metrics\n",
    "print(f\"Polynomial Regression Validation MAE (Transformed)  with {degree} polynomial degree: {poly_val_mae_transformed}\")\n",
    "print(f\"Polynomial Regression Validation MSE (Transformed)  with {degree} polynomial degree: {poly_val_mse_transformed}\")\n",
    "print(f\"Polynomial Regression Validation RMSE (Transformed)  with {degree} polynomial degree: {poly_val_rmse_transformed}\")\n",
    "print(f\"Polynomial Regression Validation R2 (Transformed)  with {degree} polynomial degree: {poly_val_r2_transformed}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The results shows that target transformation in polynomial regression did improve the performance slightly.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting pipeline for Ridge Regression \n",
    "ridge_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', Ridge(random_state=42))\n",
    "])\n",
    "\n",
    "\n",
    "ridge_pipeline.fit(X_train, y_train)\n",
    "y_val_pred_ridge = ridge_pipeline.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate regression metrics for validation set with Ridge Regression\n",
    "val_mae_ridge = mean_absolute_error(y_val, y_val_pred_ridge)\n",
    "val_mse_ridge = mean_squared_error(y_val, y_val_pred_ridge)\n",
    "val_rmse_ridge = root_mean_squared_error(y_val, y_val_pred_ridge)  \n",
    "val_r2_ridge = r2_score(y_val, y_val_pred_ridge)\n",
    "\n",
    "# Print the metrics for Ridge Regression\n",
    "print(\"Ridge Regression Metrics:\")\n",
    "print(f\"Ridge Regression polynomial degree:{degree} Validation MAE: {val_mae_ridge}\")\n",
    "print(f\"Ridge Regression polynomial degree:{degree} MSE: {val_mse_ridge}\")\n",
    "print(f\"Ridge Regression polynomial degree:{degree} RMSE: {val_rmse_ridge}\")\n",
    "print(f\"Ridge Regression polynomial degree:{degree} R²: {val_r2_ridge}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Transformation for Ridge \n",
    "TransformedTargetRegressor_model = TransformedTargetRegressor(\n",
    "    regressor    = ridge_pipeline,\n",
    "    transformer  = PowerTransformer(method='yeo-johnson')\n",
    ")\n",
    "TransformedTargetRegressor_model.fit(X_train, y_train)\n",
    "y_val_pred_ridge_transformed = TransformedTargetRegressor_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate regression metrics for validation set with Ridge Regression\n",
    "val_mae_ridge_transformed = mean_absolute_error(y_val, y_val_pred_ridge_transformed)\n",
    "val_mse_ridge_transformed = mean_squared_error(y_val, y_val_pred_ridge_transformed)\n",
    "val_rmse_ridge_transformed = root_mean_squared_error(y_val, y_val_pred_ridge_transformed)  \n",
    "val_r2_ridge_transformed = r2_score(y_val, y_val_pred_ridge_transformed)\n",
    "\n",
    "# Print the metrics for Ridge Regression\n",
    "print(\"Ridge Regression Metrics:\")\n",
    "print(f\"Ridge Regression polynomial degree:{degree} Target Transformation Validation MAE: {val_mae_ridge_transformed}\")\n",
    "print(f\"Ridge Regression polynomial degree:{degree} Target Transformation MSE: {val_mse_ridge_transformed}\")\n",
    "print(f\"Ridge Regression polynomial degree:{degree} Target Transformation RMSE: {val_rmse_ridge_transformed}\")\n",
    "print(f\"Ridge Regression polynomial degree:{degree} Target Transformation R²: {val_r2_ridge_transformed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.exceptions import ConvergenceWarning\n",
    "ConvergenceWarning('ignore')\n",
    "\n",
    "# Fit Lasso Regression with default alpha\n",
    "lasso_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', Lasso(alpha = 0.001, max_iter=3000, random_state=42))\n",
    "])\n",
    "\n",
    "TransformedTargetRegressor_model = TransformedTargetRegressor(\n",
    "    regressor    = lasso_pipeline,\n",
    "    transformer  = PowerTransformer(method='yeo-johnson')\n",
    ")\n",
    "TransformedTargetRegressor_model.fit(X_train, y_train)\n",
    "y_val_pred_lasso = TransformedTargetRegressor_model.predict(X_val)\n",
    "\n",
    "# Calculate regression metrics for validation set with Lasso Regression\n",
    "val_mae_lasso_transformed = mean_absolute_error(y_val, y_val_pred_lasso)\n",
    "val_mse_lasso_transformed = mean_squared_error(y_val, y_val_pred_lasso)\n",
    "val_rmse_lasso_transformed = root_mean_squared_error(y_val, y_val_pred_lasso)  # RMSE is the square root of MSE\n",
    "val_r2_lasso_transformed = r2_score(y_val, y_val_pred_lasso)\n",
    "\n",
    "# Display the metrics for Lasso Regression\n",
    "print(\"Lasso Regression Metrics:\")\n",
    "print(f\"Lasso Transformed Validation MAE: {val_mae_lasso_transformed}\")\n",
    "print(f\"Lasso Transformed Validation MSE: {val_mse_lasso_transformed}\")\n",
    "print(f\"Lasso Transformed Validation RMSE: {val_rmse_lasso_transformed}\")\n",
    "print(f\"Lasso Transformed Validation R²: {val_r2_lasso_transformed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.exceptions import ConvergenceWarning\n",
    "ConvergenceWarning('ignore')\n",
    "\n",
    "# Fit Lasso Regression with default alpha\n",
    "lasso_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', Lasso(alpha=0.001, max_iter=3000, random_state=42))\n",
    "])\n",
    "\n",
    "lasso_pipeline.fit(X_train, y_train)\n",
    "y_val_pred_lasso = lasso_pipeline.predict(X_val)\n",
    "\n",
    "# Calculate regression metrics for validation set with Lasso Regression\n",
    "val_mae_lasso = mean_absolute_error(y_val, y_val_pred_lasso)\n",
    "val_mse_lasso = mean_squared_error(y_val, y_val_pred_lasso)\n",
    "val_rmse_lasso = root_mean_squared_error(y_val, y_val_pred_lasso)  # RMSE is the square root of MSE\n",
    "val_r2_lasso = r2_score(y_val, y_val_pred_lasso)\n",
    "\n",
    "# Display the metrics for Lasso Regression\n",
    "print(\"Lasso Regression Metrics:\")\n",
    "print(f\"Lasso Validation MAE: {val_mae_lasso}\")\n",
    "print(f\"Lasso Validation MSE: {val_mse_lasso}\")\n",
    "print(f\"Lasso Validation RMSE: {val_rmse_lasso}\")\n",
    "print(f\"Lasso Validation R²: {val_r2_lasso}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huber Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an experiment on Huber Regression as no transformation is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = 2  # Degree of polynomial features, can be adjusted\n",
    "# Create a numerical transformer pipeline\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('polynomial_features', PolynomialFeatures(degree=degree)),  # Placeholder for polynomial features\n",
    "    ('scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('nom', nominal_transformer, nominal_features),\n",
    "        ('pass', 'passthrough', passthrough_features) \n",
    "    ],\n",
    "    remainder='passthrough',\n",
    "    n_jobs=-1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting pipeline for Huber Regression \n",
    "huber_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', HuberRegressor(epsilon=1.35, max_iter=3000, alpha=0.001)) # usually 1.35 epsilon\n",
    "])\n",
    "\n",
    "\n",
    "huber_pipeline.fit(X_train, y_train)\n",
    "y_val_pred_huber = huber_pipeline.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate regression metrics for validation set with Huber Regression\n",
    "val_mae_huber = mean_absolute_error(y_val, y_val_pred_huber)\n",
    "val_mse_huber = mean_squared_error(y_val, y_val_pred_huber)\n",
    "val_rmse_huber = root_mean_squared_error(y_val, y_val_pred_huber)  \n",
    "val_r2_huber = r2_score(y_val, y_val_pred_huber)\n",
    "\n",
    "# Display the metrics for Huber Regression\n",
    "print(\"Huber Regression Metrics:\")\n",
    "print(f\"Huber Validation MAE: {val_mae_huber}\")\n",
    "print(f\"Huber Validation MSE: {val_mse_huber}\")\n",
    "print(f\"Huber Validation RMSE: {val_rmse_huber}\")\n",
    "print(f\"Huber Validation R²: {val_r2_huber}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantile Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an experiment on Quantile regression to check the performance against traditional linear models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform train test split\n",
    "X_train_q, _, y_train_q, _ = train_test_split(X_train, y_train, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting pipeline for Quantile Regression (mid quantile)\n",
    "quantile_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', QuantileRegressor(quantile=0.5))\n",
    "])\n",
    "\n",
    "quantile_pipeline.fit(X_train, y_train)\n",
    "y_val_pred_quant_5 = quantile_pipeline.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate regression metrics for validation set with Quantile Regression\n",
    "val_mae_quant_5 = mean_absolute_error(y_val, y_val_pred_quant_5)\n",
    "val_mse_quant_5 = mean_squared_error(y_val, y_val_pred_quant_5)\n",
    "val_rmse_quant_5 = root_mean_squared_error(y_val, y_val_pred_quant_5)  \n",
    "val_r2_quant_5 = r2_score(y_val, y_val_pred_quant_5)\n",
    "\n",
    "# Display the metrics for Quantile Regression\n",
    "print(\"Quantile Regression Metrics:\")\n",
    "print(f\"Quantile Validation MAE: {val_mae_quant_5}\")\n",
    "print(f\"Quantile Validation MSE: {val_mse_quant_5}\")\n",
    "print(f\"Quantile Validation RMSE: {val_rmse_quant_5}\")\n",
    "print(f\"Quantile Validation R²: {val_r2_quant_5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting pipeline for Quantile Regression (top end quantile)\n",
    "quantile_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', QuantileRegressor(quantile=0.9))\n",
    "])\n",
    "\n",
    "quantile_pipeline.fit(X_train, y_train)\n",
    "y_val_pred_quant_9 = quantile_pipeline.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate regression metrics for validation set with Quantile Regression\n",
    "val_mae_quant_9 = mean_absolute_error(y_val, y_val_pred_quant_9)\n",
    "val_mse_quant_9 = mean_squared_error(y_val, y_val_pred_quant_9)\n",
    "val_rmse_quant_9 = root_mean_squared_error(y_val, y_val_pred_quant_9)  \n",
    "val_r2_quant_9 = r2_score(y_val, y_val_pred_quant_9)\n",
    "\n",
    "# Display the metrics for Quantile Regression\n",
    "print(\"Quantile Regression Metrics:\")\n",
    "print(f\"Quantile Validation MAE: {val_mae_quant_9}\")\n",
    "print(f\"Quantile Validation MSE: {val_mse_quant_9}\")\n",
    "print(f\"Quantile Validation RMSE: {val_rmse_quant_9}\")\n",
    "print(f\"Quantile Validation R²: {val_r2_quant_9}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quantile and Huber Regression did not outperform traditional linear model. We will compare metric on Polynomial, Ridge and Lasso Regression.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Model Metric Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add metrics to dictionary for each model with category\n",
    "metrics_poly = {\n",
    "    \"Category\": \"Original\",\n",
    "    \"Model\": \"Polynomial Regression\",\n",
    "    \"MAE\":  poly_val_mae,\n",
    "    \"RMSE\": poly_val_rmse,\n",
    "    \"R2\":   poly_val_r2,\n",
    "}\n",
    "\n",
    "metrics_poly_transformed = {\n",
    "    \"Category\": \"Target Transformed\",\n",
    "    \"Model\": \"Polynomial Regression\",\n",
    "    \"MAE\":  poly_val_mae_transformed,\n",
    "    \"RMSE\": poly_val_rmse_transformed,\n",
    "    \"R2\":   poly_val_r2_transformed,\n",
    "}\n",
    "\n",
    "metrics_ridge = {\n",
    "    \"Category\": \"Original\",\n",
    "    \"Model\": \"Ridge Regression\",\n",
    "    \"MAE\":  val_mae_ridge,\n",
    "    \"RMSE\": val_rmse_ridge,\n",
    "    \"R2\":   val_r2_ridge,\n",
    "}\n",
    "\n",
    "metrics_ridge_transformed = {\n",
    "    \"Category\": \"Target Transformed\",\n",
    "    \"Model\": \"Ridge Regression\",\n",
    "    \"MAE\":  val_mae_ridge_transformed,\n",
    "    \"RMSE\": val_rmse_ridge_transformed,\n",
    "    \"R2\":   val_r2_ridge_transformed,\n",
    "}\n",
    "\n",
    "metrics_lasso = {\n",
    "    \"Category\": \"Original\",\n",
    "    \"Model\": \"Lasso Regression\",\n",
    "    \"MAE\":  val_mae_lasso,\n",
    "    \"RMSE\": val_rmse_lasso,\n",
    "    \"R2\":   val_r2_lasso,\n",
    "}\n",
    "\n",
    "metrics_lasso_transformed = {\n",
    "    \"Category\": \"Target Transformed\",\n",
    "    \"Model\": \"Lasso Regression\",\n",
    "    \"MAE\":  val_mae_lasso_transformed,\n",
    "    \"RMSE\": val_rmse_lasso_transformed,\n",
    "    \"R2\":   val_r2_lasso_transformed,\n",
    "}\n",
    "\n",
    "# Append all metrics dictionaries to the results list\n",
    "all_results = [\n",
    "    metrics_poly,\n",
    "    metrics_ridge,\n",
    "    metrics_lasso,\n",
    "    metrics_poly_transformed,\n",
    "    metrics_ridge_transformed,\n",
    "    metrics_lasso_transformed\n",
    "]\n",
    "\n",
    "# Create DataFrame with multi-level index\n",
    "results_df = (\n",
    "    pd.DataFrame(all_results)\n",
    "      .set_index([\"Category\", \"Model\"])\n",
    "      .round(4)\n",
    ")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"MODEL PERFORMANCE COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(results_df.to_string())\n",
    "\n",
    "# Alternative: Create separate sections with cleaner display\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL PERFORMANCE - SEPARATED BY TRANSFORMATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Group by category and display each section\n",
    "for category in results_df.index.get_level_values('Category').unique():\n",
    "    print(f\"\\n{category.upper()} MODELS:\")\n",
    "    print(\"-\" * 80)\n",
    "    section_df = results_df.loc[category].round(4)\n",
    "    print(section_df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regularization will reduce validation performance, but the difference is not that huge if we are looking at R2 or MAE. We need further fine tuning and apply the model to the test set before we can decide who model to use. However, we will try Decision Tree model since our target are non-linear.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Based Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', numerical_features),\n",
    "        ('nom', nominal_transformer, nominal_features),\n",
    "        ('pass', 'passthrough', passthrough_features) \n",
    "    ],\n",
    "    remainder='passthrough',\n",
    "    n_jobs=-1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Regressor\n",
    "\n",
    "dt_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', DecisionTreeRegressor(random_state=42))\n",
    "])\n",
    "dt_pipeline.fit(X_train, y_train)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the validation set with Decision Tree Regressor\n",
    "y_val_pred_dt = dt_pipeline.predict(X_val)  \n",
    "# Calculate regression metrics for validation set with Decision Tree Regressor\n",
    "val_mae_dt = mean_absolute_error(y_val, y_val_pred_dt)\n",
    "val_mse_dt = mean_squared_error(y_val, y_val_pred_dt)\n",
    "val_rmse_dt = root_mean_squared_error(y_val, y_val_pred_dt)\n",
    "val_r2_dt = r2_score(y_val, y_val_pred_dt)  \n",
    "\n",
    "# Display the metrics for Decision Tree Regressor\n",
    "print(\"Decision Tree Regressor Metrics:\")\n",
    "print(f\"Decision Tree Validation MAE: {val_mae_dt}\")\n",
    "print(f\"Decision Tree Validation MSE: {val_mse_dt}\")\n",
    "print(f\"Decision Tree Validation RMSE: {val_rmse_dt}\")\n",
    "print(f\"Decision Tree Validation R²: {val_r2_dt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the feature importance\n",
    "dt_feature_importances = dt_pipeline.named_steps['regressor'].feature_importances_\n",
    "dt_feature_names = preprocessor.get_feature_names_out()\n",
    "dt_feature_importances_df = pd.DataFrame({'Feature': dt_feature_names, 'Importance': dt_feature_importances})\n",
    "dt_feature_importances_df = dt_feature_importances_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Print the feature importances\n",
    "print(\"\\nDecision Tree Feature Importances (Top 20):\")\n",
    "print(dt_feature_importances_df[:20])  # Display top 20 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using basic decision tree model without any parameter tuning, our error reduced and performance improve is much better than Linear Regression with transformed target. We have a MAE of $33K and R-squared of 92%. We believe that any parameter fine tuning on linear model will not be able to outperform the decision tree base line model. We will stop using linear models and adopt tree-based model as our recommended model.**\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regressor\n",
    "rf_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(random_state=42, n_jobs=-1))\n",
    "])\n",
    "rf_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on the validation set with Random Forest Regressor\n",
    "y_val_pred_rf = rf_pipeline.predict(X_val)\n",
    "\n",
    "# Calculate regression metrics for validation set with Random Forest Regressor\n",
    "val_mae_rf = mean_absolute_error(y_val, y_val_pred_rf)\n",
    "val_mse_rf = mean_squared_error(y_val, y_val_pred_rf)\n",
    "val_rmse_rf = root_mean_squared_error(y_val, y_val_pred_rf)\n",
    "val_r2_rf = r2_score(y_val, y_val_pred_rf)\n",
    "\n",
    "# Display the metrics for Random Forest Regressor\n",
    "print(\"Random Forest Regressor Metrics:\")\n",
    "print(f\"Random Forest Validation MAE: {val_mae_rf}\")\n",
    "print(f\"Random Forest Validation MSE: {val_mse_rf}\")\n",
    "print(f\"Random Forest Validation RMSE: {val_rmse_rf}\")\n",
    "print(f\"Random Forest Validation R²: {val_r2_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the feature importances for Random Forest\n",
    "rf_feature_importances = rf_pipeline.named_steps['regressor'].feature_importances_\n",
    "rf_feature_names = preprocessor.get_feature_names_out()\n",
    "rf_feature_importances_df = pd.DataFrame({'Feature': rf_feature_names, 'Importance': rf_feature_importances})\n",
    "rf_feature_importances_df = rf_feature_importances_df.sort_values(by='Importance', ascending=False)\n",
    "# Print the feature importances for Random Forest\n",
    "print(\"\\nRandom Forest Feature Importances (Top 20):\")\n",
    "print(rf_feature_importances_df[:20])  # Display top 20 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost Regressor\n",
    "xgb_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', xgb.XGBRegressor(random_state=42, n_jobs=-1, verbosity=0))\n",
    "])\n",
    "xgb_pipeline.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on the validation set with XGBoost Regressor\n",
    "y_val_pred_xgb = xgb_pipeline.predict(X_val)\n",
    "\n",
    "# Calculate regression metrics for validation set with XGBoost Regressor\n",
    "val_mae_xgb = mean_absolute_error(y_val, y_val_pred_xgb)\n",
    "val_mse_xgb = mean_squared_error(y_val, y_val_pred_xgb)\n",
    "val_rmse_xgb = root_mean_squared_error(y_val, y_val_pred_xgb)\n",
    "val_r2_xgb = r2_score(y_val, y_val_pred_xgb)\n",
    "\n",
    "# Display the metrics for XGBoost Regressor\n",
    "print(\"XGBoost Regressor Metrics:\")\n",
    "print(f\"XGBoost Validation MAE: {val_mae_xgb}\")\n",
    "print(f\"XGBoost Validation MSE: {val_mse_xgb}\")\n",
    "print(f\"XGBoost Validation RMSE: {val_rmse_xgb}\")\n",
    "print(f\"XGBoost Validation R²: {val_r2_xgb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the feature importances of XGBoost\n",
    "xgb_feature_importances = xgb_pipeline.named_steps['regressor'].feature_importances_\n",
    "xgb_feature_names = preprocessor.get_feature_names_out()\n",
    "xgb_feature_importances_df = pd.DataFrame({'Feature': xgb_feature_names, 'Importance': xgb_feature_importances})\n",
    "xgb_feature_importances_df = xgb_feature_importances_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Print the feature importances of XGBoost\n",
    "print(\"\\nXGBoost Feature Importances (Top 20):\")\n",
    "print(xgb_feature_importances_df[:20])  # Display top 20 features   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM Regressor\n",
    "lgb_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', lgb.LGBMRegressor(random_state=42, n_jobs=-1, verbosity=-1))\n",
    "])\n",
    "lgb_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on the validation set with LightGBM Regressor\n",
    "y_val_pred_lgb = lgb_pipeline.predict(X_val)\n",
    "\n",
    "# Calculate regression metrics for validation set with LightGBM Regressor\n",
    "val_mae_lgb = mean_absolute_error(y_val, y_val_pred_lgb)\n",
    "val_mse_lgb = mean_squared_error(y_val, y_val_pred_lgb)\n",
    "val_rmse_lgb = root_mean_squared_error(y_val, y_val_pred_lgb)\n",
    "val_r2_lgb = r2_score(y_val, y_val_pred_lgb)\n",
    "\n",
    "# Display the metrics for LightGBM Regressor\n",
    "print(\"LightGBM Regressor Metrics:\")\n",
    "print(f\"LightGBM Validation MAE: {val_mae_lgb}\")\n",
    "print(f\"LightGBM Validation MSE: {val_mse_lgb}\")\n",
    "print(f\"LightGBM Validation RMSE: {val_rmse_lgb}\")\n",
    "print(f\"LightGBM Validation R²: {val_r2_lgb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the feature importances of LightGBM\n",
    "lgb_feature_importances = lgb_pipeline.named_steps['regressor'].feature_importances_\n",
    "lgb_feature_names = preprocessor.get_feature_names_out()\n",
    "lgb_feature_importances_df = pd.DataFrame({'Feature': lgb_feature_names, 'Importance': lgb_feature_importances})\n",
    "lgb_feature_importances_df = lgb_feature_importances_df.sort_values(by='Importance', ascending=False)\n",
    "# Print the feature importances of LightGBM\n",
    "print(\"\\nLightGBM Feature Importances (Top 20):\")\n",
    "print(lgb_feature_importances_df[:20])  # Display top 20 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add ing metrics to dictionary for each model\n",
    "metrics_dt = {\n",
    "    \"Model\": \"Decision Tree\",\n",
    "    \"MAE\":  val_mae_dt,\n",
    "    \"RMSE\": val_rmse_dt,\n",
    "    \"R2\":   val_r2_dt,\n",
    "}\n",
    "\n",
    "metrics_lgb = {\n",
    "    \"Model\": \"LightGBM\",\n",
    "    \"MAE\":  val_mae_lgb,\n",
    "    \"RMSE\": val_rmse_lgb,\n",
    "    \"R2\":   val_r2_lgb,\n",
    "}\n",
    "\n",
    "metrics_rf = {\n",
    "    \"Model\": \"Random Forest\",\n",
    "    \"MAE\":  val_mae_rf,\n",
    "    \"RMSE\": val_rmse_rf,\n",
    "    \"R2\":   val_r2_rf,\n",
    "}\n",
    "\n",
    "metrics_xgb = {\n",
    "    \"Model\": \"XGBoost\",\n",
    "    \"MAE\":  val_mae_xgb,\n",
    "    \"RMSE\": val_rmse_xgb,\n",
    "    \"R2\":   val_r2_xgb,\n",
    "}\n",
    "\n",
    "\n",
    "all_results = [metrics_dt, metrics_rf, metrics_xgb, metrics_lgb]\n",
    "\n",
    "results_df = (\n",
    "    pd.DataFrame(all_results)\n",
    "      .set_index(\"Model\")\n",
    "      .round(4)          # nice, tidy formatting\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saved for final sanity check\n",
    "dt_default_model = dt_pipeline\n",
    "rf_default_model = rf_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Without any parameters tuning, Random Forest shows the most promising results, followed by XGBoost and LightGBM. We will use the 3 models for further hyperparameter tuning. Decision tree without tuning will be the base line model for sanity check.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MSE is too difficult to interpret and thus we have dropped it from the analysis. We will be using MAE, RMSE and R-squared. We should look at all the different performance metrics MAE, RMSE and R2 because different performance metric present different information. MAE measure the magnitude of errors but it is less sensitive to outliers. RMSE penalized large errors and helps to identify if you have large outliers. R2 tell us how much of the variation in the target are explainable by our model. However, it cannot tell us if the predictions are bias.**\n",
    "\n",
    "**Our analysis above shows that RMSE and larger than MAE indicating that there are outliers that RMSE amplified. We will not use RMSE as we do not want to penalized the squared error since the outliers are the high end housing market that our property firm would want to served. Our R-squared are consistently high indicating that our tree-based models can explain the variation in the target better. However, the differences between difference R-squared could not help us to explain the metrics further. In conclusion, we would use MAE as our primary metrics as it is also easier to explained to the management of the property firm.**   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grid Search Strategy**\n",
    "\n",
    "We will use **MAE** as the main metric because it is most easy to be understood by the stakeholder.\n",
    "\n",
    "We have performed fine tuning with a 3 stage parameters fine tuning starting with **Randomized Search** for stage 1 using the widest search space. Then we will use **Halving Randomized Search** based on the search result of stage 1 and finally, we will use **Optuna Search** to finalized the search parameters.\n",
    "\n",
    "However, after several hours of fine tuning, our MAE did improved a few hundred dollars. This is not acceptable as the improvement is marginal compared to the resource we have put in. Thus we will be using randomized search  with ranges around the default as sanity check.\n",
    "\n",
    "For further fine tuning, we will be using optuna with 5 cross validation folder around our searched parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search CV Parameters Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define RansomizedSearchCV parameters with wide search space for Decision Tree Regressor, Random Forest Regressor, XGBoost Regressor, and LightGBM Regressor\n",
    "\n",
    "rf_param_grid = {\n",
    "    'regressor__n_estimators':    [100, 200, 300],       \n",
    "    'regressor__max_depth':       [40, 50, 60],           \n",
    "    'regressor__min_samples_split': [2, 5, 7, 10],\n",
    "    'regressor__min_samples_leaf':  [1, 5, 7, 10],\n",
    "    'regressor__max_features':      ['sqrt', 'log2', 0.5, 1.0]\n",
    "}   \n",
    "\n",
    "xgb_param_grid = {\n",
    "    'regressor__n_estimators': [50, 100, 200],      \n",
    "    'regressor__max_depth': [3, 5, 7, 9],\n",
    "    'regressor__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'regressor__subsample': [0.6, 0.8, 1.0],\n",
    "    'regressor__colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'regressor__gamma': [0, 0.1, 0.2],\n",
    "    'regressor__reg_alpha': [0, 0.1, 1],\n",
    "    'regressor__reg_lambda': [0, 0.1, 1]\n",
    "}   \n",
    "\n",
    "lgb_param_grid = {\n",
    "    'regressor__n_estimators': [50, 100, 200],\n",
    "    'regressor__max_depth': [3, 5, 7, 9],\n",
    "    'regressor__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'regressor__num_leaves': [31, 63, 127],\n",
    "    'regressor__min_child_samples': [20, 30, 40],\n",
    "    'regressor__subsample': [0.6, 0.8, 1.0],\n",
    "    'regressor__colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'regressor__reg_alpha': [0, 0.1, 1],\n",
    "    'regressor__reg_lambda': [0, 0.1, 1]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random_search = RandomizedSearchCV(\n",
    "    rf_pipeline,\n",
    "    param_distributions=rf_param_grid,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    n_iter=5,\n",
    "    cv=3,\n",
    "    verbose=3,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform randomized search for XGBoost Regressor\n",
    "xgb_random_search = RandomizedSearchCV(\n",
    "    xgb_pipeline,\n",
    "    param_distributions=xgb_param_grid,\n",
    "    n_iter=60,  # Number of iterations for random search\n",
    "    scoring='neg_mean_absolute_error',   \n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    verbose=3,\n",
    "    random_state=42,\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "xgb_random_search.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform randomized search for LightGBM Regressor\n",
    "lgb_random_search = RandomizedSearchCV(\n",
    "    lgb_pipeline,\n",
    "    param_distributions=lgb_param_grid,\n",
    "    n_iter=30,  # Number of iterations for random search\n",
    "    scoring='neg_mean_absolute_error',       \n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    verbose=3,\n",
    "    random_state=42,\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "lgb_random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best parameters and best score for Random Forest Regressor\n",
    "print(\"Best parameters for Random Forest Regressor:\", rf_random_search.best_params_)\n",
    "print(\"Best score for Random Forest Regressor (negative MSE):\", rf_random_search.best_score_)\n",
    "# Print the best parameters and best score for XGBoost Regressor\n",
    "print(\"Best parameters for XGBoost Regressor:\", xgb_random_search.best_params_)\n",
    "print(\"Best score for XGBoost Regressor (negative MSE):\", xgb_random_search.best_score_)\n",
    "# Print the best parameters and best score for LightGBM Regressor\n",
    "print(\"Best parameters for LightGBM Regressor:\", lgb_random_search.best_params_)\n",
    "print(\"Best score for LightGBM Regressor (negative MSE):\", lgb_random_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The difference between the best model is not that great. Will perform fine tuning and select the best few for final model evaluation test.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optuna Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tight_distributions(best_params,\n",
    "                             int_frac: float = 0.2,\n",
    "                             float_frac: float = 0.1,\n",
    "                             min_int_step: int = 1):\n",
    "    \"\"\"\n",
    "    Given a dict of best_params_, return a dict of\n",
    "    Optuna Distributions that span ±frac around each value.\n",
    "    \"\"\"\n",
    "    tight_dists = {}\n",
    "    for name, val in best_params.items():\n",
    "        # only handle numeric params\n",
    "        if isinstance(val, int):\n",
    "            # window = max(val * int_frac, min_int_step)\n",
    "            window = max(int(val * int_frac), min_int_step)\n",
    "            low  = max(1, val - window)      # avoid zero or negative\n",
    "            high = val + window\n",
    "            # choose step = min_int_step or window itself\n",
    "            step = min_int_step if min_int_step <= window else window\n",
    "            tight_dists[name] = IntDistribution(low=low, high=high, step=step)\n",
    "\n",
    "        elif isinstance(val, float):\n",
    "            window = val * float_frac\n",
    "            low  = max(0.0, val - window)\n",
    "            high = min(1.0, val + window)    # assuming [0,1] support for fractions\n",
    "            tight_dists[name] = FloatDistribution(low=low, high=high)\n",
    "\n",
    "        else:\n",
    "            # skip non-numeric (e.g. categorical) or handle separately\n",
    "            continue\n",
    "\n",
    "    return tight_dists\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Optuna Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. grab your previously-found best params:\n",
    "best_rf_random_search = rf_random_search.best_params_\n",
    "\n",
    "# 2. build the “around-the-best” distributions:\n",
    "rf_param_distributions = make_tight_distributions(best_rf_random_search,\n",
    "                                               int_frac=0.2,     # ±20%\n",
    "                                               float_frac=0.1,   # ±10%\n",
    "                                               min_int_step=1)   # at least step=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_param_distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Optuna quick search\n",
    "optuna_search = OptunaSearchCV(\n",
    "    estimator=rf_pipeline,\n",
    "    param_distributions=rf_param_distributions,\n",
    "    cv=5,             \n",
    "    n_trials=2,      \n",
    "    scoring='neg_mean_absolute_error',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=3,\n",
    ")\n",
    "\n",
    "# 4. Run the search\n",
    "optuna_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Inspect results\n",
    "print(\"Best MAE  =\", optuna_search.best_score_)\n",
    "print(\"Best params:\")\n",
    "for k, v in optuna_search.best_params_.items():\n",
    "    print(f\"  • {k} = {v}\")\n",
    "\n",
    "# 6. Your final model\n",
    "final_rf_model = optuna_search.best_estimator_\n",
    "final_rf_model_params = optuna_search.best_params_\n",
    "final_rf_model_scores = optuna_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_final_rf_model_pred = final_rf_model.predict(X_val)\n",
    "\n",
    "# 7. Calculate regression metrics for validation set with Random Forest Regressor\n",
    "final_val_mae_rf = mean_absolute_error(y_val, val_final_rf_model_pred)\n",
    "final_val_mse_rf = mean_squared_error(y_val, val_final_rf_model_pred)\n",
    "final_val_rmse_rf = root_mean_squared_error(y_val, val_final_rf_model_pred)\n",
    "final_val_r2_rf = r2_score(y_val, val_final_rf_model_pred)\n",
    "\n",
    "# 8. Display the metrics for Random Forest Regressor\n",
    "print(\"Random Forest Regressor Metrics:\")\n",
    "print(f\"Random Forest Validation MAE: {final_val_mae_rf}\")\n",
    "print(f\"Random Forest Validation MSE: {final_val_mse_rf}\")\n",
    "print(f\"Random Forest Validation RMSE: {final_val_rmse_rf}\")\n",
    "print(f\"Random Forest Validation R²: {final_val_r2_rf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost Optuna Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. grab your previously-found best params:\n",
    "best_xgb_random_search_param = xgb_random_search.best_params_\n",
    "\n",
    "# 2. build the “around-the-best” distributions:\n",
    "xgb_param_distributions = make_tight_distributions(best_xgb_random_search_param,\n",
    "                                               int_frac=0.2,     # ±20%\n",
    "                                               float_frac=0.1,   # ±10%\n",
    "                                               min_int_step=1)   # at least step=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_param_distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Optuna quick search\n",
    "optuna_search = OptunaSearchCV(\n",
    "    estimator=xgb_pipeline,\n",
    "    param_distributions=xgb_param_distributions,\n",
    "    cv=5,             \n",
    "    n_trials=50,      \n",
    "    scoring='neg_mean_absolute_error',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=3,\n",
    ")\n",
    "\n",
    "# 4. Run the search\n",
    "optuna_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Inspect results\n",
    "print(\"Best MAE  =\", optuna_search.best_score_)\n",
    "print(\"Best params:\")\n",
    "for k, v in optuna_search.best_params_.items():\n",
    "    print(f\"  • {k} = {v}\")\n",
    "\n",
    "# 6. Your final model\n",
    "final_xgb_model = optuna_search.best_estimator_\n",
    "final_xgb_model_params = optuna_search.best_params_\n",
    "final_xgb_model_scores = optuna_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_final_xgb_model = final_xgb_model.predict(X_val)\n",
    "\n",
    "# 7. Calculate regression metrics for validation set with Random Forest Regressor\n",
    "final_val_mae_xgb = mean_absolute_error(y_val, val_final_xgb_model)\n",
    "final_val_mse_xgb = mean_squared_error(y_val, val_final_xgb_model)\n",
    "final_val_rmse_xgb = root_mean_squared_error(y_val, val_final_xgb_model)\n",
    "final_val_r2_xgb = r2_score(y_val, val_final_xgb_model)\n",
    "\n",
    "# 8. Display the metrics for Random Forest Regressor\n",
    "print(\"Random Forest Regressor Metrics:\")\n",
    "print(f\"Random Forest Validation MAE: {final_val_mae_xgb}\")\n",
    "print(f\"Random Forest Validation MSE: {final_val_mse_xgb}\")\n",
    "print(f\"Random Forest Validation RMSE: {final_val_rmse_xgb}\")\n",
    "print(f\"Random Forest Validation R²: {final_val_r2_xgb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Light GBM Optuna Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. grab your previously-found best params:\n",
    "best_lgb_random_search_param = lgb_random_search.best_params_\n",
    "\n",
    "# 2. build the “around-the-best” distributions:\n",
    "lgb_param_distributions = make_tight_distributions(best_lgb_random_search_param,\n",
    "                                               int_frac=0.2,     # ±20%\n",
    "                                               float_frac=0.1,   # ±10%\n",
    "                                               min_int_step=1)   # at least step=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_param_distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Optuna quick search\n",
    "optuna_search = OptunaSearchCV(\n",
    "    estimator=lgb_pipeline,\n",
    "    param_distributions=lgb_param_distributions,\n",
    "    cv=5,             \n",
    "    n_trials=30,      \n",
    "    scoring='neg_mean_absolute_error',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=3,\n",
    ")\n",
    "\n",
    "# 4. Run the search\n",
    "optuna_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Inspect results\n",
    "print(\"Best MAE  =\", optuna_search.best_score_)\n",
    "print(\"Best params:\")\n",
    "for k, v in optuna_search.best_params_.items():\n",
    "    print(f\"  • {k} = {v!r}\")\n",
    "\n",
    "# 6. Your final model\n",
    "final_lgb_model = optuna_search.best_estimator_\n",
    "final_lgb_model_params = optuna_search.best_params_\n",
    "final_lgb_model_scores = optuna_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_final_lgb_model = final_lgb_model.predict(X_val)\n",
    "\n",
    "# 7. Calculate regression metrics for validation set with Random Forest Regressor\n",
    "final_val_mae_lgb = mean_absolute_error(y_val, val_final_lgb_model)\n",
    "final_val_mse_lgb = mean_squared_error(y_val, val_final_lgb_model)\n",
    "final_val_rmse_lgb = root_mean_squared_error(y_val, val_final_lgb_model)\n",
    "final_val_r2_lgb = r2_score(y_val, val_final_lgb_model)\n",
    "\n",
    "# 8. Display the metrics for Random Forest Regressor\n",
    "print(\"Random Forest Regressor Metrics:\")\n",
    "print(f\"Random Forest Validation MAE: {final_val_mae_lgb}\")\n",
    "print(f\"Random Forest Validation MSE: {final_val_mse_lgb}\")\n",
    "print(f\"Random Forest Validation RMSE: {final_val_rmse_lgb}\")\n",
    "print(f\"Random Forest Validation R²: {final_val_r2_lgb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing Fine Tuned Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best parameters and best score for Random Forest Regressor\n",
    "print(\"Best parameters for Random Forest Regressor:\", final_rf_model_params)\n",
    "print(\"Best score for Random Forest Regressor (negative MSE):\", final_rf_model_scores)\n",
    "# Print the best parameters and best score for XGBoost Regressor\n",
    "print(\"Best parameters for XGBoost Regressor:\", final_xgb_model_params)\n",
    "print(\"Best score for XGBoost Regressor (negative MSE):\", final_xgb_model_scores)\n",
    "# Print the best parameters and best score for LightGBM Regressor\n",
    "print(\"Best parameters for LightGBM Regressor:\", final_lgb_model_params)\n",
    "print(\"Best score for LightGBM Regressor (negative MSE):\", final_lgb_model_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of Fine Tuned Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First, we apply the default decision tree as baseline for sanity check.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the validation set with the default Decision Tree Regressor\n",
    "y_val_pred_dt_default = dt_default_model.predict(X_val)\n",
    "# Calculate regression metrics for validation set with the default Decision Tree Regressor\n",
    "val_mae_dt_default = mean_absolute_error(y_val, y_val_pred_dt_default)\n",
    "val_rmse_dt_default = root_mean_squared_error(y_val, y_val_pred_dt_default)\n",
    "val_r2_dt_default = r2_score(y_val, y_val_pred_dt_default)\n",
    "\n",
    "# Display the metrics for the default Decision Tree Regressor\n",
    "print(\"Default Decision Tree Regressor Metrics:\")\n",
    "print(f\"Default Decision Tree Validation MAE: {val_mae_dt_default}\")\n",
    "print(f\"Default Decision Tree Validation RMSE: {val_rmse_dt_default}\")\n",
    "print(f\"Default Decision Tree Validation R²: {val_r2_dt_default}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next, we try Random Forest with default settings as it has a good score before fine tuning.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set with the default Random Forest Regressor\n",
    "y_val_pred_rf_default = rf_default_model.predict(X_val)\n",
    "# Calculate regression metrics for test set with the default Random Forest Regressor\n",
    "val_mae_rf_default = mean_absolute_error(y_val, y_val_pred_rf_default)\n",
    "val_rmse_rf_default = root_mean_squared_error(y_val, y_val_pred_rf_default)\n",
    "val_r2_rf_default = r2_score(y_val, y_val_pred_rf_default)\n",
    "\n",
    "# Display the metrics for the default Random Forest Regressor\n",
    "print(\"Default Random Forest Regressor Metrics:\")\n",
    "print(f\"Default Random Forest Validation MAE: {val_mae_rf_default}\")\n",
    "print(f\"Default Random Forest Validation RMSE: {val_rmse_rf_default}\")\n",
    "print(f\"Default Random Forest Validation R²: {val_r2_rf_default}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on the validation set with the best Random Forest Regressor\n",
    "y_val_pred_rf_best = final_rf_model.predict(X_val)\n",
    "# Calculate regression metrics for validation set with the best Random Forest Regressor\n",
    "val_mae_rf_best = mean_absolute_error(y_val, y_val_pred_rf_best)\n",
    "val_rmse_rf_best = root_mean_squared_error(y_val, y_val_pred_rf_best)\n",
    "val_r2_rf_best = r2_score(y_val, y_val_pred_rf_best)    \n",
    "\n",
    "# Display the metrics for the best Random Forest Regressor\n",
    "print(\"Best Random Forest Regressor Metrics:\")\n",
    "print(f\"Best Random Forest Validation MAE: {val_mae_rf_best}\")\n",
    "print(f\"Best Random Forest Validation RMSE: {val_rmse_rf_best}\")\n",
    "print(f\"Best Random Forest Validation R²: {val_r2_rf_best}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on the validation set with the best xgboost Regressor\n",
    "y_val_pred_xgb_best = final_xgb_model.predict(X_val)\n",
    "# Calculate regression metrics for validation set with the best XGBoost Regressor\n",
    "val_mae_xgb_best = mean_absolute_error(y_val, y_val_pred_xgb_best)\n",
    "val_rmse_xgb_best = root_mean_squared_error(y_val, y_val_pred_xgb_best)\n",
    "val_r2_xgb_best = r2_score(y_val, y_val_pred_xgb_best)  \n",
    "# Display the metrics for the best XGBoost Regressor\n",
    "print(\"Best XGBoost Regressor Metrics:\")\n",
    "print(f\"Best XGBoost Validation MAE: {val_mae_xgb_best}\")       \n",
    "print(f\"Best XGBoost Validation RMSE: {val_rmse_xgb_best}\")\n",
    "print(f\"Best XGBoost Validation R²: {val_r2_xgb_best}\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on the validation set with the best lightgbm Regressor\n",
    "y_val_pred_lgb_best = final_lgb_model.predict(X_val)\n",
    "# Calculate regression metrics for validation set with the best LightGBM Regressor\n",
    "val_mae_lgb_best = mean_absolute_error(y_val, y_val_pred_lgb_best)\n",
    "val_rmse_lgb_best = root_mean_squared_error(y_val, y_val_pred_lgb_best)\n",
    "val_r2_lgb_best = r2_score(y_val, y_val_pred_lgb_best)\n",
    "# Display the metrics for the best LightGBM Regressor\n",
    "print(\"Best LightGBM Regressor Metrics:\")\n",
    "print(f\"Best LightGBM Validation MAE: {val_mae_lgb_best}\")\n",
    "print(f\"Best LightGBM Validation RMSE: {val_rmse_lgb_best}\")\n",
    "print(f\"Best LightGBM Validation R²: {val_r2_lgb_best}\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add ing metrics to dictionary for each model\n",
    "metrics_rf_default = {\n",
    "    \"Model\": \"Random Forest (def)\",\n",
    "    \"MAE\":  val_mae_rf_default,\n",
    "    \"RMSE\": val_rmse_rf_default,\n",
    "    \"R2\":   val_r2_rf_default,\n",
    "}\n",
    "\n",
    "metrics_rf = {\n",
    "    \"Model\": \"Random Forest\",\n",
    "    \"MAE\":  val_mae_rf_best,\n",
    "    \"RMSE\": val_rmse_rf_best,\n",
    "    \"R2\":   val_r2_rf_best,\n",
    "}\n",
    "\n",
    "metrics_xgb = {\n",
    "    \"Model\": \"XGBoost\",\n",
    "    \"MAE\":  val_mae_xgb_best,\n",
    "    \"RMSE\": val_rmse_xgb_best,\n",
    "    \"R2\":   val_r2_xgb_best,\n",
    "}\n",
    "\n",
    "metrics_lgb = {\n",
    "    \"Model\": \"LightGBM\",\n",
    "    \"MAE\":  val_mae_lgb_best,\n",
    "    \"RMSE\": val_rmse_lgb_best,\n",
    "    \"R2\":   val_r2_lgb_best,\n",
    "}\n",
    "\n",
    "all_results = [metrics_rf_default, metrics_rf, metrics_xgb, metrics_lgb]\n",
    "\n",
    "results_df = (\n",
    "    pd.DataFrame(all_results)\n",
    "      .set_index(\"Model\")\n",
    "      .round(4)          # nice, tidy formatting\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Our best model is XGBoost with MAE of $23,338 margin or errors.**\n",
    "\n",
    "**All MAE are very close. In our experience, model with the best validation score may not do well in the test. Therefore, we will apply all the 4 models into the test set. We will deploy model with the best score.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set with the default Random Forest Regressor\n",
    "y_test_pred_rf_default = rf_default_model.predict(X_test)\n",
    "# Calculate regression metrics for test set with the default Random Forest Regressor\n",
    "test_mae_rf_default = mean_absolute_error(y_test, y_test_pred_rf_default)\n",
    "test_rmse_rf_default = root_mean_squared_error(y_test, y_test_pred_rf_default)\n",
    "test_r2_rf_default = r2_score(y_test, y_test_pred_rf_default)\n",
    "\n",
    "# Display the metrics for the default Random Forest Regressor\n",
    "print(\"Default Random Forest Regressor Metrics:\")\n",
    "print(f\"Default Random Forest Test MAE: {test_mae_rf_default}\")\n",
    "print(f\"Default Random Forest Test RMSE: {test_rmse_rf_default}\")\n",
    "print(f\"Default Random Forest Test R²: {test_r2_rf_default}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set with the best Random Forest Regressor\n",
    "y_test_pred_rf_best = final_rf_model.predict(X_test)\n",
    "# Calculate regression metrics for test set with the best Random Forest Regressor\n",
    "test_mae_rf_best = mean_absolute_error(y_test, y_test_pred_rf_best)\n",
    "test_rmse_rf_best = root_mean_squared_error(y_test, y_test_pred_rf_best)\n",
    "test_r2_rf_best = r2_score(y_test, y_test_pred_rf_best)\n",
    "\n",
    "# Display the metrics for the best Random Forest Regressor\n",
    "print(\"Best Random Forest Regressor Metrics:\")\n",
    "print(f\"Best Random Forest Test MAE: {test_mae_rf_best}\")\n",
    "print(f\"Best Random Forest Test RMSE: {test_rmse_rf_best}\")\n",
    "print(f\"Best Random Forest Test R²: {test_r2_rf_best}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set with the best XGBoost Regressor\n",
    "y_test_pred_xgb_best = final_xgb_model.predict(X_test)\n",
    "# Calculate regression metrics for test set with the best XGBoost Regressor\n",
    "test_mae_xgb_best = mean_absolute_error(y_test, y_test_pred_xgb_best)\n",
    "test_rmse_xgb_best = root_mean_squared_error(y_test, y_test_pred_xgb_best)\n",
    "test_r2_xgb_best = r2_score(y_test, y_test_pred_xgb_best)\n",
    "\n",
    "# Display the metrics for the best XGBoost Regressor\n",
    "print(\"Best XGBoost Regressor Metrics:\")\n",
    "print(f\"Best XGBoost Regressor Test MAE: {test_mae_xgb_best}\")\n",
    "print(f\"Best XGBoost Regressor Test RMSE: {test_rmse_xgb_best}\")\n",
    "print(f\"Best XGBoost Regressor Test R²: {test_r2_xgb_best}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set with the best LightGBM Regressor\n",
    "y_test_pred_lgb_best = final_lgb_model.predict(X_test)\n",
    "# Calculate regression metrics for test set with the best LightGBM Regressor\n",
    "test_mae_lgb_best = mean_absolute_error(y_test, y_test_pred_lgb_best)\n",
    "test_rmse_lgb_best = root_mean_squared_error(y_test, y_test_pred_lgb_best)\n",
    "test_r2_lgb_best = r2_score(y_test, y_test_pred_lgb_best)\n",
    "\n",
    "# Display the metrics for the best LightGBM Regressor\n",
    "print(\"Best LightGBM Regressor Metrics:\")\n",
    "print(f\"Best LightGBM Regressor Test MAE: {test_mae_lgb_best}\")\n",
    "print(f\"Best LightGBM Regressor Test RMSE: {test_rmse_lgb_best}\")\n",
    "print(f\"Best LightGBM Regressor Test R²: {test_r2_lgb_best}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The best model is still XGBoost. MAE result is similar to validation test. This confirms that our test set is representative of the validation datasets.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model from Optuna Search\n",
    "best_model = final_xgb_model\n",
    "\n",
    "# Predict on the test set with Ridge Regression\n",
    "y_test_pred_best_model = best_model.predict(X_test)\n",
    "\n",
    "# Calculate regression metrics for the test set for Ridge\n",
    "test_mae_best = mean_absolute_error(y_test, y_test_pred_best_model)\n",
    "test_rmse_best = root_mean_squared_error(y_test, y_test_pred_best_model)\n",
    "test_r2_best = r2_score(y_test, y_test_pred_best_model)\n",
    "\n",
    "print(\"Best Ridge Regression Model, Final Test Metrics:\")\n",
    "print(f\"Final Test MAE: {test_mae_best}\")\n",
    "print(f\"Final Test RMSE: {test_rmse_best}\")\n",
    "print(f\"Final Test R²: {test_r2_best}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hdbenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
